

## Papers for 2025-05-19

| Title | Authors | Summary |
|-------|---------|---------|
| Qwen3 Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.09388) or [HuggingFace](https://huggingface.co/papers/2505.09388))| huybery, BeichenZhang, Baosong, laf070810, yangapku | i) Qwen3, the latest iteration of the Qwen model family, is introduced as a series of open-source large language models designed for enhanced performance, efficiency, and multilingual capabilities. ii) The objective is to advance performance, efficiency, and multilingual capabilities in large language models. iii) The methodology involves pre-training on 36 trillion tokens, integrating thinking and non-thinking modes, and a multi-stage post-training approach including long chain-of-thought finetuning, reinforcement learning, and strong-to-weak distillation. iv) Qwen3-235B-A22B achieves 85.7 on AIME'24 and expands multilingual support to 119 languages, demonstrating state-of-the-art results across diverse benchmarks. v) AI practitioners can leverage Qwen3's unified thinking mode and thinking budget mechanism to adaptively allocate computational resources during inference, balancing latency and performance based on task complexity.  |
| MMLongBench: Benchmarking Long-Context Vision-Language Models
  Effectively and Thoroughly (Read more on [arXiv](https://arxiv.org/abs/2505.10610) or [HuggingFace](https://huggingface.co/papers/2505.10610))| Yu Zhao, Jipeng Zhang, Xiyu Ren, Wenhao Yu, Zhaowei Wang | i) MMLONGBENCH is introduced as the first benchmark for evaluating long-context vision-language models (LCVLMs). ii) The research aims to provide an effective and thorough evaluation of LCVLMs across a diverse set of tasks. iii) The methodology involves curating a dataset of 13,331 examples spanning five downstream task categories and assessing 46 closed-source and open-source LCVLMs across standardized input lengths. iv) Results indicate that performance on a single task is a weak proxy for overall long-context capability, and models with stronger reasoning exhibit better long-context performance; at 128K tokens, even GPT-4o only achieves 62.9% on average. v) The benchmark and associated analysis highlight the need for improved vision-language long-context capabilities and a more comprehensive evaluation approach for future LCVLM development.  |
| GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.11049) or [HuggingFace](https://huggingface.co/papers/2505.11049))| Tri Cao, Yulin Chen, Mingzhe Du, Shengfang Zhai, Yue Liu | i) GuardReasoner-VL, a novel reasoning-based VLM guard model, is introduced to enhance safety by incentivizing deliberative reasoning before moderation decisions via online reinforcement learning (RL). ii) The primary research objective is to improve the safety of Vision-Language Models (VLMs) without compromising their core capabilities by developing a guard model that reasons about harmful content before moderating. iii) The methodology involves constructing a reasoning corpus, GuardReasoner-VLTrain, with 123K samples and 631K reasoning steps, followed by supervised fine-tuning (SFT) and online RL with safety-aware data concatenation and a dynamic clipping parameter. iv) Experiments demonstrate that GuardReasoner-VL surpasses the runner-up by 19.27% F1 score on average on multi-modal guardrail benchmarks. v) The principal implication for AI practitioners is a new, reasoning-based approach to VLM safety that can be implemented via online RL, offering a potential framework for developing more robust and interpretable guard models.  |
| Visual Planning: Let's Think Only with Images (Read more on [arXiv](https://arxiv.org/abs/2505.11409) or [HuggingFace](https://huggingface.co/papers/2505.11409))| ivulic, akorhonen, caiqizh, masonxw, hzhouml | i) The paper introduces Visual Planning, a novel paradigm for machine reasoning using solely visual representations. ii) The main objective is to investigate whether models can effectively plan through visual representations without textual mediation. iii) The methodology involves a reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), utilizing GRPO for post-training large vision models. iv) Experiments on spatial navigation tasks (FROZENLAKE, MAZE, MINIBEHAVIOR) show that VPRL achieves over 40% higher average exact-match rate compared to supervised fine-tuning (SFT). v) Visual Planning offers AI practitioners a viable alternative to language-based reasoning for tasks with inherent spatial or geometric properties, potentially reducing the modality gap in multimodal tasks.  |
| Simple Semi-supervised Knowledge Distillation from Vision-Language
  Models via texttt{D}ual-texttt{H}ead
  texttt{O}ptimization (Read more on [arXiv](https://arxiv.org/abs/2505.07675) or [HuggingFace](https://huggingface.co/papers/2505.07675))| Sung Ju Hwang, Hyungjoon Jang, Seongjae Kang, dongboklee | i) This paper introduces Dual-Head Optimization (DHO), a knowledge distillation framework for vision-language models in semi-supervised learning. ii) The objective is to transfer knowledge from large VLMs to compact, task-specific models while addressing gradient conflicts in semi-supervised settings. iii) DHO utilizes dual prediction heads independently trained with supervised and distillation losses and combines their outputs linearly at inference. iv) Experiments show DHO improves accuracy by 3% on ImageNet with 1% labeled data compared to existing methods. v) DHO offers AI practitioners a more efficient distillation method that mitigates gradient conflicts, improving feature learning for knowledge transfer in resource-constrained environments.  |
| Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token
  Level Granularity (Read more on [arXiv](https://arxiv.org/abs/2505.11107) or [HuggingFace](https://huggingface.co/papers/2505.11107))| Yi-Chang Chen, Feng-Ting Liao, Jamie McGowan, Davide Buffelli, Splend1dchan | i) The paper introduces Group Think, a novel LLM inference paradigm enabling token-level collaborative reasoning among concurrent agents to improve quality and latency. ii) The primary objective is to develop a more efficient and higher-quality reasoning framework for LLMs by leveraging multiple concurrent reasoning agents. iii) The methodology involves modifying existing LLMs to support multiple interdependent, parallel reasoning trajectories with token-level adaptation among agents, evaluated on enumeration, divide-and-conquer, and coding tasks. iv) Empirical results show Group Think improves reasoning accuracy while reducing latency on open-source LLMs, demonstrating an acceleration of roughly N (number of thinkers) times faster than CoT, with Completion Coverage becoming near saturated. v) Group Think offers AI practitioners a method for enhancing reasoning performance, especially in resource-constrained edge inference scenarios, by efficiently utilizing idle computational resources through concurrent reasoning.  |
| Mergenetic: a Simple Evolutionary Model Merging Library (Read more on [arXiv](https://arxiv.org/abs/2505.11427) or [HuggingFace](https://huggingface.co/papers/2505.11427))| erodola, crisostomi, teelinsan, tmencatt, adrianrob | i) Mergenetic is introduced as an open-source library for evolutionary model merging in LLMs. ii) The research aims to facilitate experimentation with evolutionary algorithms and merging methods, while reducing the computational cost of fitness evaluations. iii) The library integrates 19 evolutionary algorithms and 6 merging strategies, incorporating dataset subsampling and fitness approximation techniques. iv) Experiments demonstrate that Mergenetic achieves competitive results across tasks and languages, with merged models outperforming language-specific constituents by up to 19% on the ARC-Challenge benchmark. v) The library's modular design and user-friendly interfaces (Python API, CLI, GUI) enable AI practitioners to efficiently explore high-quality model compositions on consumer-grade GPUs.  |
| MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective
  Search and Data Curation (Read more on [arXiv](https://arxiv.org/abs/2505.10962) or [HuggingFace](https://huggingface.co/papers/2505.10962))| Tao Yang, Yang Li, haitaominlp, freesunshine0316, invokerliang | i) The paper introduces MPS-Prover, a stepwise automated theorem proving system utilizing multi-perspective search and data curation. ii) The main objective is to improve stepwise theorem proving performance by mitigating biased search guidance and enhancing exploration. iii) The methodology involves a post-training data curation strategy to prune redundant training data and a multi-perspective tree search mechanism integrating a learned critic with heuristic rules. iv) MPS-Prover achieves a 75.82% accuracy on the miniF2F benchmark, surpassing previous stepwise provers, and obtains a 32.97% success rate on ProofNet. v) The work provides AI practitioners with a robust framework for developing more powerful theorem provers and demonstrates the efficacy of combining learned critics with heuristic search in formal reasoning systems.  |
| Multi-Token Prediction Needs Registers (Read more on [arXiv](https://arxiv.org/abs/2505.10518) or [HuggingFace](https://huggingface.co/papers/2505.10518))| Nikos Komodakis, Spyros Gidaris, nasos10 | i) The paper introduces MuToR, a novel multi-token prediction method for improving language model pretraining and finetuning by interleaving learnable register tokens into input sequences. ii) The main objective is to develop a multi-token prediction approach that enhances autoregressive transformers without architectural changes, enabling scalable prediction horizons and preserving compatibility with pretrained models. iii) The method involves training register tokens to predict future targets at varying offsets while using a designed attention mask to maintain the standard next-token prediction for regular tokens. iv) Experiments on language modeling show that MuToR improves performance in supervised and parameter-efficient finetuning, surpassing standard baselines under equivalent compute; in mathematical reasoning with Gemma 2B, MuToR achieved 42.10% accuracy on GSM8K, outperforming Next-Token at 38.87%. v) MuToR provides AI practitioners with a readily integrable technique for improving model performance and training efficiency in generative tasks across both language and vision domains, particularly in scenarios benefiting from enhanced forward-looking context during training.  |
| Learning Dense Hand Contact Estimation from Imbalanced Data (Read more on [arXiv](https://arxiv.org/abs/2505.11152) or [HuggingFace](https://huggingface.co/papers/2505.11152))| kyoungmu, dqj5182 | Learning dense hand contact estimation is addressed by mitigating class and spatial imbalance in hand interaction datasets. The research aims to improve dense hand contact estimation by addressing class and spatial imbalance issues in training data. Balanced Contact Sampling (BCS) constructs multiple sampling groups to represent diverse contact statistics, while Vertex-Level Class-Balanced (VCB) loss reweights loss contribution of each vertex based on its contact frequency. The method achieves improved performance in dense hand contact estimation across diverse scenarios, evidenced by a 10.4% increase in F1-score on the MOW dataset compared to models without BCS. AI practitioners can use the proposed techniques to effectively train hand contact estimation models on imbalanced datasets, improving performance in areas such as robotics and AR/VR.  |
| Scaling Reasoning can Improve Factuality in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.11140) or [HuggingFace](https://huggingface.co/papers/2505.11140))| rubis, bjerva, jjzha | i) This paper investigates methods for improving factual accuracy in LLMs through reasoning and knowledge graph integration. ii) The research question is to what extent long reasoning influences factual generalization capabilities of large language models on complex multi-hop questions. iii) The methodology involves distilling reasoning traces from QwQ-32B and DeepSeek-R1-671B, fine-tuning Qwen2.5 models with these traces, and incorporating knowledge graph paths via Wikidata. iv) The primary result shows that smaller instruction-tuned models can improve factual accuracy with KG-enhanced reasoning traces, and increasing test-time compute by parallel scaling improves factual accuracy by 2-8%. v) The principal implication is that within a single run, smaller reasoning models can achieve improvements in factual accuracy compared to their original instruction-tuned counterparts in Open-Domain QA.  |
| Humans expect rationality and cooperation from LLM opponents in
  strategic games (Read more on [arXiv](https://arxiv.org/abs/2505.11011) or [HuggingFace](https://huggingface.co/papers/2505.11011))| Miguel Costa-Gomes, Darija Barak | i) This paper investigates human strategic behavior in p-beauty contests against LLM opponents. ii) The study aims to understand how human choices differ when playing against LLMs versus other humans in a multiplayer game setting without dominant strategies. iii) The methodology involves a monetarily-incentivized laboratory experiment using a within-subject design to compare behavior against human and LLM (ChatGPT 3.5 and Claude v2) opponents. iv) Results show that subjects choose significantly lower numbers against LLMs, driven by an increased rate of zero choices, with 15.3% making zero choices against LLMs compared to 4.2% against humans; additionally, 16.7% of subjects were classified as possessing high strategic reasoning ability. v) AI practitioners should account for the potential of humans to overestimate LLMsâ€™ strategic sophistication or cooperativeness when designing human-AI interactive systems, impacting mechanism design and agent behavior predictions. The paper does not contain a clearly-defined quantitative measure related to cooperation.  |
| MatTools: Benchmarking Large Language Models for Materials Science Tools (Read more on [arXiv](https://arxiv.org/abs/2505.10852) or [HuggingFace](https://huggingface.co/papers/2505.10852))| David J. Srolovitz, Bo Hu, Beilin Ye, Jiamin Xu, SiyuLiu | MatTools introduces a benchmark to evaluate large language models (LLMs) proficiency in materials science through code generation and execution. The research aims to assess LLMs' ability to answer materials science questions by generating codes based on physics-based computational materials science packages. MatTools employs a two-component framework: a materials simulation tool question-answer (QA) benchmark with 69,225 pairs from pymatgen and a real-world tool-usage benchmark of 49 tasks (138 subtasks). Evaluation of various LLMs revealed that general-purpose LLMs significantly outperformed materials science-focused LLMs, achieving 80% versus <32% accuracy in QA tasks, and LLM-generated documentation substantially improved performance in retrieval-augmented generation (RAG) systems. The principal implication for AI practitioners is the demonstration of leveraging LLM-generated documentation and self-reflection mechanisms to enhance LLM tool-use abilities in technical domains like materials science, potentially guiding the development of more effective AI systems for scientific research, while highlighting the limitations of domain-specific LLMs.  |
