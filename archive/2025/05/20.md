

## Papers for 2025-05-20

| Title | Authors | Summary |
|-------|---------|---------|
| Chain-of-Model Learning for Language Model (Read more on [arXiv](https://arxiv.org/abs/2505.11820) or [HuggingFace](https://huggingface.co/papers/2505.11820))| tricktreat, Chengruidong, iofu728, xutan, KaitaoSong | i) The paper proposes Chain-of-Model (CoM), a learning paradigm for language models that introduces scaling efficiency and deployment flexibility. ii) The primary objective is to develop a framework for progressively scaling up language models and enabling elastic inference with varying model sizes. iii) The methodology involves incorporating Chain-of-Representation (CoR) into Transformer layers, termed Chain-of-Language-Model (CoLM), and introducing a KV sharing mechanism (CoLM-Air) for extensibility. iv) Experimental results demonstrate that CoLM achieves comparable performance to standard Transformers while enabling capabilities such as progressive scaling and offering multiple sub-models for elastic inference. v) The CoLM framework enables AI practitioners to progressively scale language models and deploy them in resource-constrained environments by selecting appropriate sub-model sizes for inference.  |
| AdaptThink: Reasoning Models Can Learn When to Think (Read more on [arXiv](https://arxiv.org/abs/2505.13417) or [HuggingFace](https://huggingface.co/papers/2505.13417))| Ling Feng, Lei Hou, juanli, linny2002, NeoZ123 | i) This paper introduces AdaptThink, a reinforcement learning (RL) algorithm for reasoning models to adaptively select between Thinking and NoThinking modes based on problem difficulty. ii) The primary research objective is to enable reasoning models to dynamically choose the optimal thinking mode to balance reasoning quality and efficiency. iii) The methodology involves a constrained optimization objective that encourages the NoThinking mode and an importance sampling strategy to balance Thinking and NoThinking samples during on-policy RL training. iv) Experiments on math datasets show that AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4% on three math datasets (GSM8K, MATH500, and AIME2024). v) The principal implication for AI practitioners is the potential for adaptive thinking-mode selection to optimize the trade-off between reasoning quality and inference costs in large reasoning models.  |
| AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.11896) or [HuggingFace](https://huggingface.co/papers/2505.11896))| Shuangzhi, qingping95, Swtheking, sunzewei2715, louchenwei | AdaCoT introduces a reinforcement learning framework for adaptive Chain-of-Thought (CoT) triggering in large language models (LLMs) to optimize performance and cost. The research addresses the challenge of indiscriminate CoT usage by framing adaptive reasoning as a Pareto optimization problem. The methodology employs proximal policy optimization (PPO) with selective loss masking (SLM) to dynamically control CoT triggering based on query complexity. Experiments show AdaCoT reduces CoT triggering rates to 3.18% on production traffic, decreasing average response tokens by 69.06% while maintaining performance on complex tasks. AdaCoT offers AI practitioners a method for developing more efficient and cost-effective LLMs by dynamically adjusting reasoning based on query complexity.  |
| Delta Attention: Fast and Accurate Sparse Attention Inference by Delta
  Correction (Read more on [arXiv](https://arxiv.org/abs/2505.11254) or [HuggingFace](https://huggingface.co/papers/2505.11254))| Sung Ju Hwang, gmlwns5176, jeffwillette | Here is a summary of the provided AI research paper:  i) This paper introduces Delta Attention (∆ Attention), a method for correcting distributional shifts in sparse attention mechanisms to improve accuracy during inference. ii) The research aims to mitigate the performance degradation observed in sparse attention methods for long sequences by addressing the distributional shift they induce. iii) The methodology involves calculating the difference between sparse and full attention outputs on a subset of queries and applying this difference as a correction to the sparse attention output. iv) The primary result is an average 36%pt performance increase in accuracy compared to existing sparse attention methods, recovering 88% of full quadratic attention accuracy on the 131K RULER benchmark with sliding window attention and sink tokens, while maintaining 98.5% sparsity, achieving 32x faster inference than Flash Attention 2 when processing 1M token prefills. v) The principal implication for AI practitioners is a more accurate and efficient sparse attention mechanism for transformer models that can be seamlessly integrated into existing pipelines to improve performance in long-sequence tasks.  |
| Scaling Computer-Use Grounding via User Interface Decomposition and
  Synthesis (Read more on [arXiv](https://arxiv.org/abs/2505.13227) or [HuggingFace](https://huggingface.co/papers/2505.13227))| Mayome, RadioBlue, lixiaochuan2020, MillanK, tianbaoxiexxx | i) This paper introduces OSWORLD-G, a GUI grounding benchmark, and JEDI, a large-scale synthetic dataset. ii) The primary objective is to address the limitations of existing GUI grounding benchmarks by creating a more comprehensive and challenging evaluation environment. iii) The research utilizes a multi-perspective decoupling of tasks to synthesize the JEDI dataset and trains multi-scale models on this data. iv) Results show improved grounding performance on ScreenSpot-v2, ScreenSpot-Pro, and OSWORLD-G, with agentic capabilities on complex computer tasks improving from 5% to 27% on OSWorld. v) AI practitioners can leverage the JEDI dataset and OSWORLD-G benchmark to develop more robust GUI grounding models, leading to enhanced agentic capabilities in complex computer tasks.  |
| Thinkless: LLM Learns When to Think (Read more on [arXiv](https://arxiv.org/abs/2505.13379) or [HuggingFace](https://huggingface.co/papers/2505.13379))| wxcTest, horseee, Vinnnf | i) Thinkless is a reinforcement learning framework enabling Language Models (LLMs) to adaptively select between short-form and long-form reasoning modes. ii) The main research question is whether LLMs can learn to decide when to engage in elaborate reasoning based on task complexity and model capability. iii) The methodology involves training LLMs under a reinforcement learning paradigm using Decoupled Group Relative Policy Optimization (DeGRPO) with control tokens for reasoning modes. iv) Thinkless reduces the usage of long-chain thinking by 50%-90% on benchmarks like Minerva Algebra and GSM8K. v) The principal implication for AI practitioners is a method for significantly improving the efficiency of reasoning LLMs by adaptively controlling the depth of reasoning, reducing computational costs while preserving task performance.  |
| Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient
  in Latent Space (Read more on [arXiv](https://arxiv.org/abs/2505.13308) or [HuggingFace](https://huggingface.co/papers/2505.13308))| zlzheng, vickyandkekey, ColorfulAI, xuekai, henry12348 | i) The paper introduces LATENTSEEK, a novel framework for enhancing LLM reasoning via test-time instance-level adaptation (TTIA) in the model's latent space. ii) The research aims to improve LLM reasoning capabilities at test time without parameter updating by optimizing latent representations guided by self-generated reward signals. iii) The key methodology involves using policy gradient to iteratively update latent representations based on a self-generated reward function operating within the model's latent space. iv) Results show that LATENTSEEK achieves an average improvement of 10.75% over Chain-of-Thought on the GSM8K dataset. v) AI practitioners can leverage LATENTSEEK as a lightweight and scalable solution to enhance the reasoning capabilities of LLMs without extensive retraining or fine-tuning.  |
| MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable
  Step-Level Supervision (Read more on [arXiv](https://arxiv.org/abs/2505.13427) or [HuggingFace](https://huggingface.co/papers/2505.13427))| wqshao126, Domingo12, SuperposedWave, FanqingM, Cierra0506 | i) The paper introduces MM-PRM, a process reward model for enhancing multimodal mathematical reasoning through scalable step-level supervision. ii) The research aims to improve logical robustness in multimodal reasoning systems by providing fine-grained supervision over intermediate steps. iii) The methodology includes building a multimodal policy model (MM-Policy), curating the MM-K12 dataset, and generating step-level annotations using a Monte Carlo Tree Search (MCTS) pipeline for training the process reward model. iv) Experiments show MM-PRM improves accuracy on the MM-K12 test set from 33.92% to 42.80% using best-of-N inference and demonstrates generalization to out-of-domain benchmarks such as MathVista and OlympiadBench. v) MM-PRM provides AI practitioners with a process reward model and a framework that enhance the logical consistency of multimodal reasoning systems, demonstrating the effectiveness of process supervision in improving mathematical problem-solving.  |
| Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation (Read more on [arXiv](https://arxiv.org/abs/2505.13215) or [HuggingFace](https://huggingface.co/papers/2505.13215))| epark, Heyjin, LeeYG, ohseungjun | Hybrid 3D-4D Gaussian Splatting (3D-4DGS) is introduced for efficient dynamic scene representation. The study addresses the computational and memory overhead in dynamic 3D scene reconstruction by adaptively representing static regions with 3D Gaussians and dynamic elements with 4D Gaussians. The method iteratively converts temporally invariant Gaussians into 3D, reducing parameters and improving computational efficiency. Experiments show the approach achieves comparable rendering quality with a significantly faster training time, converging in approximately 12 minutes compared to other 4DGS methods. The hybrid 3D-4D representation allows AI practitioners to achieve faster training and reduced memory consumption when reconstructing dynamic scenes, enabling more efficient development of real-time rendering applications.  |
| FedSVD: Adaptive Orthogonalization for Private Federated Learning with
  LoRA (Read more on [arXiv](https://arxiv.org/abs/2505.12805) or [HuggingFace](https://huggingface.co/papers/2505.12805))| Sangwoo Park, hbseong, dwgnr, dongboklee, Seanie-lee | i) The paper introduces FedSVD, a federated learning method that adapts LoRA weights using SVD for improved privacy and performance. ii) The research aims to mitigate noise amplification in differentially private federated learning with LoRA by adaptively updating the low-rank adaptation matrix. iii) The methodology involves a server performing SVD on aggregated LoRA updates and reinitializing the orthogonal matrix A, while clients optimize matrix B with DP-SGD. iv) Experiments on GLUE datasets under DP constraints (ε = 6, δ = 10−5) show that FedSVD achieves a 8.77 percentage point increase over FFA-LoRA. v) The key implication for AI practitioners is a stable and efficient method to fine-tune large language models in privacy-sensitive federated learning settings by reparameterizing LoRA updates.  |
| CPGD: Toward Stable Rule-based Reinforcement Learning for Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2505.12504) or [HuggingFace](https://huggingface.co/papers/2505.12504))| wqshao126, SuperposedWave, Cierra0506, FanqingM, Zkkkai | i) The paper introduces Clipped Policy Gradient Optimization with Policy Drift (CPGD) to stabilize rule-based reinforcement learning for language models. ii) The main objective is to address training instability issues in existing RL methods for LMs, specifically those related to large policy updates and improper clipping. iii) CPGD incorporates a KL divergence-based policy drift constraint to dynamically regularize policy updates, combined with a clip mechanism on the logarithm of the ratio to prevent excessive changes. iv) Empirical analysis shows that CPGD improves overall performance by +11.0% across various multimodal reasoning benchmarks compared to the base model and reduces instability. v) CPGD offers AI practitioners a more robust and stable RL algorithm for post-training language models, mitigating issues of training collapse common in methods that directly incorporate importance-sampling ratios in the loss function.  |
| Faster Video Diffusion with Trainable Sparse Attention (Read more on [arXiv](https://arxiv.org/abs/2505.13389) or [HuggingFace](https://huggingface.co/papers/2505.13389))| EricX003, hunterhector, BrianChen1129, haofeng666, PY007 | Faster Video Diffusion with Trainable Sparse Attention introduces VSA, a hardware-aligned trainable sparse attention mechanism for video Diffusion Transformers (DiTs). The research aims to mitigate the quadratic complexity of 3D attention in DiTs by focusing computation on critical tokens. VSA employs a hierarchical approach with a coarse stage for tile pooling and a fine stage for token-level attention within selected tiles, implemented with block-sparse kernels and trained end-to-end. Experiments show VSA achieves up to 2.53× reduction in training FLOPS compared to full attention with no drop in diffusion loss and accelerates Wan-2.1 attention time by 6×. VSA's efficiency and scalability present a practical alternative to full attention, enabling further scaling of video diffusion models.  |
| Fractured Chain-of-Thought Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.12992) or [HuggingFace](https://huggingface.co/papers/2505.12992))| JunnanLi, doyensahoo, yuhuixu, hendrydong, baohao | i) The paper introduces Fractured Sampling, an inference-time scaling technique for large language models (LLMs) that interpolates between full Chain-of-Thought (CoT) and solution-only sampling. ii) The research investigates how to optimize the accuracy-cost trade-off in LLM reasoning by controlling the number of reasoning trajectories, final solutions per trajectory, and reasoning trace truncation depth. iii) The methodology involves extensive experiments on five reasoning benchmarks, evaluating performance against token budget constraints by varying the number of reasoning trajectories, solution diversity, and reasoning prefix length. iv) Results demonstrate that truncated CoT often matches or exceeds full CoT accuracy with fewer tokens, and Fractured Sampling achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget with up to a 10.4% improvement over baseline on certain tasks. v) Practitioners can leverage Fractured Sampling to achieve more efficient and scalable LLM reasoning by strategically allocating computational resources across reasoning depth, trajectory diversity, and solution diversity to maximize performance within a given token budget.  |
| VisionReasoner: Unified Visual Perception and Reasoning via
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.12081) or [HuggingFace](https://huggingface.co/papers/2505.12081))| Shu Liu, BoHao0326, zszhong, TainU, Ricky06662 | VisionReasoner is a unified reinforcement learning framework for diverse visual perception tasks. The paper aims to create a single model capable of reasoning and solving multiple visual perception tasks like detection, segmentation, and counting. The methodology involves designing a multi-object cognitive learning strategy and task reformulation, using format and accuracy rewards to train a shared model via reinforcement learning. VisionReasoner achieves superior performance with a 29.1% relative improvement on COCO detection compared to Qwen2.5VL using only 7,000 training samples. VisionReasoner offers AI practitioners a unified architecture for handling various visual perception tasks, potentially streamlining development and improving generalization capabilities in resource-constrained scenarios.  |
| Neuro-Symbolic Query Compiler (Read more on [arXiv](https://arxiv.org/abs/2505.11932) or [HuggingFace](https://huggingface.co/papers/2505.11932))| jrwen, wuyongkang, lixiaoxi45, douzc, KeriaZhang | i) This paper introduces QCompiler, a neuro-symbolic framework for complex query understanding in Retrieval Augmented Generation (RAG) systems. ii) The main research objective is to improve the precision of search intent recognition for complex queries with nested structures and dependencies in RAG systems. iii) The methodology involves designing a minimal Backus-Naur Form (BNF) grammar to formalize complex queries, translating natural language queries into BNF expressions, and parsing these into Abstract Syntax Trees (ASTs) for execution. iv) Experimental results show that QCompiler achieves a 44.5% Exact Match on the 2WikiMultihopQA dataset. v) The primary implication for AI practitioners is a lightweight framework that can be integrated into existing RAG systems to improve efficiency and accuracy by providing more precise document retrieval and response generation. |
| Model Merging in Pre-training of Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.12082) or [HuggingFace](https://huggingface.co/papers/2505.12082))| Jing Liu, Chaoyi Zhang, Shen Yan, Yiyuan Ma, Yunshui Li | Model merging, specifically Pre-trained Model Average (PMA), is investigated for LLM pre-training to enhance performance and reduce training costs. The study explores how merging checkpoints during pre-training affects model performance, optimal merging strategies, and training stability. The methodology involves training dense and Mixture-of-Experts (MoE) architectures, ranging from millions to over 100 billion parameters, with extensive ablations of merging techniques. Model merging during the stable training phase achieves consistent performance gains, demonstrated by improvements such as Seed-MoE-1.3B/13B increasing from 31.1 to 36.6 on the Humaneval benchmark. PMA offers AI practitioners a cost-effective method to simulate annealed performance with constant learning rates, potentially leading to faster validation and reduced computational costs in LLM development, while also stabilizing training via weight initialization.  |
| ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.13180) or [HuggingFace](https://huggingface.co/papers/2505.13180))| Pietroferr, giobin, minttusofia, dainesn1, merlerm | i) ViPlan is a new benchmark for evaluating visual planning capabilities of Vision-Language Models (VLMs) using symbolic predicates. ii) The paper investigates how VLMs perform in visual planning tasks both as direct planners and as grounders for symbolic planners. iii) The benchmark uses a visual Blocksworld domain and a simulated household robotics environment, evaluating nine open-source VLM families and selected closed models with and without Chain-of-Thought prompting. iv) Results show VLM-grounded symbolic planning outperforms direct VLM planning in Blocksworld but the reverse is true for household robotics, also showing no significant benefit from Chain-of-Thought prompting. v) AI practitioners should note that VLM performance in visual planning is highly task-dependent, with symbolic grounding proving more useful for tasks requiring accurate image interpretation and direct VLM planning working better when benefiting from the pre-trained world knowledge.  |
| Accelerate TarFlow Sampling with GS-Jacobi Iteration (Read more on [arXiv](https://arxiv.org/abs/2505.12849) or [HuggingFace](https://huggingface.co/papers/2505.12849))| zhenqincn, encoreus | i) The paper introduces a GS-Jacobi iteration method to accelerate the sampling process in TarFlow models. ii) The research aims to improve the sampling efficiency of TarFlow models, which suffer from slow sequential computation due to the causal form of attention. iii) The methodology involves transforming the sampling process into a diagonalized nonlinear system and applying a Gauss-Seidel-Jacobi hybrid iteration scheme, along with Convergence Ranking Metric (CRM) and Initial Guessing Metric (IGM). iv) Experiments show GS-Jacobi sampling achieves a speed-up of 4.53× in Img128cond, 5.32x in AFHQ, 2.96× in Img64uncond, and 2.51x in Img64cond without degrading FID scores. v) AI practitioners can utilize GS-Jacobi sampling to significantly enhance the sampling speed of TarFlow models while preserving generation quality, potentially enabling faster deployment and experimentation.  |
| When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification
  of Scientific Research (Read more on [arXiv](https://arxiv.org/abs/2505.11855) or [HuggingFace](https://huggingface.co/papers/2505.11855))| sngwon, Cartinoe5930, HazelNam, JW17, amphora | This paper introduces SPOT, a new benchmark for automated scientific manuscript verification using large language models (LLMs). The research question explores the viability of using LLMs to automate the academic verification of scientific papers. The methodology involves creating a dataset of 83 published papers paired with 91 confirmed errors, cross-validated by authors and human annotators, and then evaluating state-of-the-art LLMs on this dataset. Results show that the best LLM achieved only 21.1% recall and 6.1% precision in error detection; furthermore confidence estimates are uniformly low and rediscovery rates are poor. The principal implication for AI practitioners is that there remains a substantial gap between current LLM capabilities and the requirements for dependable AI-assisted academic verification, indicating a need for further research and development in this area.  |
| ChartMuseum: Testing Visual Reasoning Capabilities of Large
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.13444) or [HuggingFace](https://huggingface.co/papers/2505.13444))| wadhma, PrasannSinghal, fcyin, thomlake, lytang | ChartMuseum introduces a new benchmark for evaluating visual and textual reasoning in large vision-language models (LVLMs) on chart understanding. The research aims to address the imbalance in LVLM skills, particularly the shortfall in visual reasoning compared to textual reasoning. A new Chart Question Answering (QA) benchmark called CHARTMUSEUM was created, consisting of 1,162 expert-annotated questions derived from real-world charts. The results indicate that the best-performing model Gemini-2.5-Pro achieves only 63.0% accuracy, while human performance reaches 93%, and on questions requiring primarily visual reasoning, models experience a 35%-55% performance drop. This benchmark reveals a substantial gap between model and human capabilities in chart understanding and highlights the areas of visual reasoning that present significant challenges for current LVLMs, indicating practitioners must be aware of the limitation of LVLMs' ability to reason with visual data when developing multimodal systems involving charts.  |
| MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation (Read more on [arXiv](https://arxiv.org/abs/2505.10238) or [HuggingFace](https://huggingface.co/papers/2505.10238))| Yali Wang, Zhizhi Guo, Xirui Hu, yanboding | i) MTVCrafter introduces a novel framework for human image animation directly modeling raw 3D motion sequences using a 4D motion tokenizer. ii) The research aims to improve generalization and controllability in open-world human image animation by directly modeling 4D motion instead of relying on 2D pose estimations. iii) A 4D Motion Tokenizer (4DMoT) is proposed to quantize 3D motion sequences into 4D motion tokens, and a Motion-aware Video Diffusion Transformer (MV-DiT) leverages these tokens for animation guidance. iv) MTVCrafter achieves a state-of-the-art FID-VID score of 6.98 on the TikTok dataset, surpassing the second-best method by 65%. v) MTVCrafter offers AI practitioners a new paradigm for pose-guided human video generation by enabling direct manipulation of 4D motion data for improved realism and control, though detailed architecture info is limited.  |
| FinePhys: Fine-grained Human Action Generation by Explicitly
  Incorporating Physical Laws for Effective Skeletal Guidance (Read more on [arXiv](https://arxiv.org/abs/2505.13437) or [HuggingFace](https://huggingface.co/papers/2505.13437))| Shengda Xu, Mingfei Shi, Dian Shao, Jason-Huang824, Harold328 | FinePhys is a novel framework for generating physically plausible fine-grained human action videos using skeletal guidance and physics-based motion re-estimation. The research objective is to synthesize realistic and coherent human actions, particularly for challenging tasks like gymnastics routines. The methodology employs online 2D pose estimation, 2D-to-3D lifting via in-context learning, and a physics-based motion re-estimation module (PhysNet) governed by Euler-Lagrange equations for bidirectional temporal updating. Evaluated on three fine-grained action subsets from FineGym, FinePhys significantly outperforms competitive baselines achieving a CLIP-SIM* of 0.833 compared to AnimateDiff's 0.752 on the FX-TURN dataset, thereby producing more natural human actions. FinePhys provides AI practitioners with a novel approach for incorporating physical constraints into generative models, potentially improving the realism and plausibility of generated human motion in various applications.  |
| ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.12996) or [HuggingFace](https://huggingface.co/papers/2505.12996))| Jie Zhou, fandong, Krystalan | i) The paper introduces ExTrans, a multilingual neural machine translation (MT) model trained via reinforcement learning (RL) with a novel reward modeling approach. ii) The main research objective is to improve the translation quality of large reasoning models (LRMs) in both monolingual and multilingual settings by leveraging exemplar translations. iii) The methodology employs a new reward model that compares the policy MT model's translations with those generated by a strong LRM (DeepSeek-R1) acting as an exemplar, combined with format verification for multilingual extension. iv) Experimental results show ExTrans-7B achieves state-of-the-art performance in English-to-Chinese literary translation, outperforming OpenAI-01 and DeepSeek-R1, with mExTrans-7B demonstrating competitive multilingual MT performance across 11 languages. v) This work provides AI practitioners with an effective RL-based training paradigm for MT that incorporates LLM-as-an-exemplar reward modeling and a lightweight multilingual transfer strategy, potentially reducing reliance on high-resource data and complex reward models.  |
| SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.11484) or [HuggingFace](https://huggingface.co/papers/2505.11484))| Chunyan Miao, Xu Guo, Aver3, xuyige | SoftCoT++ introduces a test-time scaling method for chain-of-thought reasoning in large language models by diversifying latent soft thought representations. The research aims to enhance LLM reasoning performance by enabling diverse exploration of thinking paths in the continuous latent space during inference. This is achieved by perturbing latent thoughts via multiple specialized initial tokens and applying contrastive learning to promote diversity among soft thought representations. Experiments on five reasoning benchmarks using LLaMA-3 and Qwen-3 show SoftCoT++ significantly boosts SoftCoT, outperforming SoftCoT with self-consistency scaling, with an average accuracy of 77.57% across all tasks using LLaMA-3.1-8B-Instruct. The primary implication is that AI practitioners can leverage SoftCoT++ to improve the reasoning capabilities of LLMs without retraining by scaling latent soft thought representations during inference, enhancing performance on complex reasoning tasks.  |
| HISTAI: An Open-Source, Large-Scale Whole Slide Image Dataset for
  Computational Pathology (Read more on [arXiv](https://arxiv.org/abs/2505.12120) or [HuggingFace](https://huggingface.co/papers/2505.12120))| Ekaterina Ivanova, alpchel, mgvz | i) The HISTAI dataset, a large, open-access resource, is introduced for computational pathology research. ii) The main objective is to provide a diverse and richly annotated whole slide image (WSI) dataset to address limitations in existing resources. iii) The methodology involves curating over 60,000 WSIs from various tissue types, accompanied by comprehensive clinical metadata including diagnoses, demographics, pathological annotations, and ICD-10 codes. iv) The HISTAI dataset includes 57,647 slides at 20X magnification and 2,463 slides at 40X magnification, with 58,282 H&E stained slides, and aims to cover a wide array of organs and cancer types. v) The HISTAI dataset provides AI practitioners with a large, multimodal resource to develop more robust, generalizable, and clinically relevant AI solutions in digital pathology.  |
| QVGen: Pushing the Limit of Quantized Video Generative Models (Read more on [arXiv](https://arxiv.org/abs/2505.11497) or [HuggingFace](https://huggingface.co/papers/2505.11497))| Jing Liu, HaotongQin, lvchengtao, Ruihao, Harahan | i) This paper introduces QVGen, a novel quantization-aware training (QAT) framework for efficient video diffusion models (DMs) under extremely low-bit quantization. ii) The main research objective is to develop a QAT method that preserves the performance of video DMs under 4-bit or lower quantization, without introducing additional inference costs. iii) QVGen incorporates auxiliary modules to reduce quantization errors and employs a rank-decay strategy using singular value decomposition (SVD) and rank-based regularization to progressively eliminate these modules during training. iv) Experiments show that QVGen achieves full-precision comparable quality under 4-bit settings and significantly outperforms existing methods, for example, a 3-bit CogVideoX-2B achieves +25.28 improvement in Dynamic Degree on VBench. v) QVGen enables AI practitioners to deploy high-quality, low-bit video DMs with minimal performance degradation and zero inference overhead, providing a practical solution for resource-constrained environments.  |
| From Grunts to Grammar: Emergent Language from Cooperative Foraging (Read more on [arXiv](https://arxiv.org/abs/2505.12872) or [HuggingFace](https://huggingface.co/papers/2505.12872))| Mingfei Sun, Wei Pan, Weicheng Tao, Rujikorn Charakorn, Maytus Piriyajitakonkij | i) This paper introduces Foraging Games (FG), a multi-agent reinforcement learning (MARL) framework for studying emergent language under embodied and socially interdependent conditions. ii) The research aims to investigate how language emerges and adapts within multi-agent systems in response to ecological and cognitive constraints relevant to cooperative foraging. iii) The methodology involves training agents via Proximal Policy Optimization (PPO) in a partially observable grid world, where agents jointly learn actions and communication strategies from scratch without parameter sharing or a centralized critic. iv) Results show agents develop communication protocols exhibiting arbitrariness, interchangeability, displacement, cultural transmission, and compositionality, with agents achieving over 95% success rates across games; with population sizes greater than 2, agents achieved an Interchangeability approaching 1.0. v) The study provides AI practitioners with a decentralized MARL framework to study emergent communication, social dynamics, and the evolution of language in embodied agents, offering insights for designing more robust and adaptable AI systems in cooperative environments.  |
| Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset
  Generation & Smoke-Tests for Continuous LLM Evaluation (Read more on [arXiv](https://arxiv.org/abs/2505.12058) or [HuggingFace](https://huggingface.co/papers/2505.12058))| vincentkoc | i) The paper introduces Tiny QA Benchmark++ (TQB++), an ultra-lightweight LLM evaluation suite, expanding on the original TQB with synthetic data generation and multilingual support. ii) The main objective is to provide a rapid, low-cost method for continuous integration and deployment (CI/CD) and smoke-testing of LLMs. iii) The methodology includes a Python script for on-demand synthetic micro-benchmark generation in multiple languages with SHA-256 hashing for provenance, along with pre-built multilingual packs. iv) Empirical results show top-tier models achieve approximately 90% Exact Match accuracy on the core English set, with significant performance variations in low-resource languages. v) TQB++ enables AI engineers to quickly detect regressions and quality shifts in LLMOps workflows through lightweight unit testing, facilitating faster iteration and more robust LLM deployments.  |
| HelpSteer3-Preference: Open Human-Annotated Preference Data across
  Diverse Tasks and Languages (Read more on [arXiv](https://arxiv.org/abs/2505.11475) or [HuggingFace](https://huggingface.co/papers/2505.11475))| Felipe Soares, Hoo-Chang Shin, Olivier Delalleau, Jiaqi Zeng, Zhilin Wang | i) The paper introduces HelpSteer3-Preference, a new open-source human-annotated preference dataset for training instruction-following language models. ii) The main objective is to improve the quality and diversity of available preference data for Reinforcement Learning from Human Feedback (RLHF). iii) The methodology involved collecting over 40,000 samples across diverse tasks including STEM, coding, and multilingual scenarios, utilizing specialist annotators. iv) Reward Models trained on HelpSteer3-Preference achieve 82.4% on RM-Bench and 73.7% on JudgeBench, a ~10% absolute improvement over existing RMs. v) AI practitioners can use HelpSteer3-Preference to train more effective reward models for aligning large language models, particularly in domains requiring specialized knowledge or multilingual capabilities.  |
| Learned Lightweight Smartphone ISP with Unpaired Data (Read more on [arXiv](https://arxiv.org/abs/2505.10420) or [HuggingFace](https://huggingface.co/papers/2505.10420))| Radu Timofte, AndreiArhire | i) This paper introduces a novel unpaired training method for a learnable Image Signal Processor (ISP) on smartphones. ii) The main objective is to develop a lightweight ISP that eliminates the need for pixel-wise aligned paired data. iii) The methodology involves a multi-term loss function guided by adversarial training with multiple discriminators processing feature maps from pre-trained networks. iv) Evaluated on the Zurich RAW to RGB dataset, the unpaired approach demonstrates potential and achieves high fidelity across evaluation metrics while maintaining a favorable perceptual quality as reflected by LPIPS scores. v) This unpaired training strategy allows AI practitioners to develop efficient ISPs without the costly acquisition of paired RAW and RGB images, enabling broader applications in resource-constrained environments like mobile devices.  |
| Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models (Read more on [arXiv](https://arxiv.org/abs/2505.12973) or [HuggingFace](https://huggingface.co/papers/2505.12973))| Hamid R. Rabiee, Zahra Dehghanian, Mahta Fetrat Qharabagh | i) This paper addresses homograph disambiguation in grapheme-to-phoneme (G2P) conversion, particularly for low-resource languages like Persian. ii) The research aims to improve homograph disambiguation accuracy in both neural and rule-based G2P systems, while maintaining low latency for real-time applications. iii) A semi-automated pipeline for constructing a homograph-focused dataset (HomoRich) was developed, along with a lightweight statistical method to enhance G2P systems. iv) Fine-tuning a state-of-the-art neural G2P model (GE2PE) on HomoRich achieved a 29.72% improvement in homograph accuracy, and integrating the statistical method into eSpeak resulted in a 30.66% improvement in homograph disambiguation. v) The HomoRich dataset and the statistical disambiguation method provide AI practitioners with resources to enhance the accuracy of both neural and rule-based G2P systems, particularly in low-resource scenarios where real-time performance is critical for applications like screen readers.  |
| LLM Context Conditioning and PWP Prompting for Multimodal Validation of
  Chemical Formulas (Read more on [arXiv](https://arxiv.org/abs/2505.12257) or [HuggingFace](https://huggingface.co/papers/2505.12257))| PChemGuy | LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas investigates methods for improving Large Language Model (LLM) accuracy in identifying errors within scientific documents, specifically chemical formulas. The main objective is to enhance the reliability of general-purpose LLMs for precise validation tasks, focusing on chemical formulas validation within a test paper containing known errors. Persistent Workflow Prompting (PWP) principles informed structured LLM context conditioning was used to modulate LLM behavior at inference time via chat interfaces of Gemini 2.5 Pro and ChatGPT Plus 03. PWP-informed context conditioning improved textual error identification with both models, and Gemini 2.5 Pro repeatedly identified a subtle image-based formula error previously overlooked. This study implies that PWP-informed context conditioning can enhance LLM-driven analytical workflows, particularly for tasks requiring meticulous error detection in scientific and technical documents.  |
| TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique
  Annotation in Cyber Threat Intelligence Text (Read more on [arXiv](https://arxiv.org/abs/2505.11988) or [HuggingFace](https://huggingface.co/papers/2505.11988))| mparvez, TahaSencar, utsavshukla, lekssays | i) TECHNIQUERAG is a domain-specific retrieval-augmented generation framework for automating adversarial technique annotation in security texts. ii) The paper addresses the research question of how to accurately identify adversarial techniques in security texts without extensive labeled data or task-specific optimizations. iii) The framework integrates off-the-shelf retrievers, instruction-tuned LLMs, and minimal text-technique pairs, using LLM re-ranking to enhance domain specificity. iv) Experiments demonstrate state-of-the-art performance on multiple security benchmarks, with TECHNIQUERAG achieving a F1 score of 91.09% on Procedures. v) The principal implication for AI practitioners is a novel approach to improving the precision of RAG systems in specialized domains with limited data.  |
| AI-Driven Scholarly Peer Review via Persistent Workflow Prompting,
  Meta-Prompting, and Meta-Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.03332) or [HuggingFace](https://huggingface.co/papers/2505.03332))| PChemGuy | This paper explores AI-driven scholarly peer review using large language models (LLMs). The research question focuses on developing a persistent workflow prompting (PWP) methodology for critical analysis by LLMs, especially for experimental chemistry manuscripts. The key methodology involves creating a hierarchical, modular prompt architecture (structured via Markdown) and iteratively refining the prompt through meta-prompting and meta-reasoning. The primary result demonstrates the LLM's ability to identify major methodological flaws, distinguishing claims from evidence, and performing quantitative feasibility checks on a test case. The principal implication for AI practitioners lies in the potential of PWP to enable sophisticated analysis of complex scientific tasks using readily available LLMs, reducing the need for custom-tailored models or extensive training data.  |
