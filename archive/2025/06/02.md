

## Papers for 2025-06-02

| Title | Authors | Summary |
|-------|---------|---------|
| ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in
  Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.24864) or [HuggingFace](https://huggingface.co/papers/2505.24864))| Xin Dong, Jian Hu, Ximing Lu, Shizhe Diao, Mingjie Liu | ProRL introduces a prolonged reinforcement learning methodology to enhance reasoning in large language models. The research explores whether RL can truly expand a model’s reasoning capabilities beyond merely amplifying existing outputs and investigates the impact of extended RL training. The methodology incorporates KL divergence control, reference policy resetting, and diverse task training, scaling up to 2k training steps. Empirical results demonstrate that RL-trained models outperform base models in pass@k evaluations, with average improvements of 14.7% on math benchmarks compared to DeepSeek-R1-1.5B, and reveals RL can uncover new solution pathways entirely absent in base models. The findings suggest that prolonged RL training can enable exploration of new reasoning patterns, holding implications for AI practitioners as it demonstrates the potential for RL to meaningfully expand reasoning boundaries in language models given sufficient training time.  |
| AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time (Read more on [arXiv](https://arxiv.org/abs/2505.24863) or [HuggingFace](https://huggingface.co/papers/2505.24863))| Haoran Geng, Xuying Ning, Han Wang, RunpeiDong, jyzhang1208 | i) This paper introduces ALPHAONE (a1), a framework for modulating reasoning progress in large reasoning models (LRMs) at test time. ii) The research aims to develop a universal approach to modulating the reasoning process of LRMs to enhance both reasoning capability and efficiency. iii) The methodology involves scaling the thinking phase using a universal parameter a, dynamically scheduling slow thinking transitions before the a moment via a Bernoulli process, and deterministically terminating slow thinking after the a moment. iv) Experiments on various benchmarks demonstrate a1's superior reasoning capability and efficiency, with the 1.5B LRM showing a Pass@1 improvement of +6.15% while reducing token length by nearly 14%. v) ALPHAONE offers AI practitioners an efficient test-time scaling strategy to modulate LRMs, improving both accuracy and efficiency across mathematical, coding, and scientific reasoning tasks, through a dense slow-to-fast reasoning modulation technique.  |
| Time Blindness: Why Video-Language Models Can't See What Humans Can? (Read more on [arXiv](https://arxiv.org/abs/2505.24867) or [HuggingFace](https://huggingface.co/papers/2505.24867))| Mohamed Elhoseiny, Zhiqiang Shen, mukul54, ujjwal9 | i) The paper introduces SpookyBench, a benchmark to evaluate purely temporal understanding in video-language models (VLMs). ii) The main research question is to assess why VLMs struggle with temporal pattern recognition when spatial cues are absent. iii) The methodology involves creating a synthetic dataset with information encoded exclusively in temporal noise sequences and evaluating various VLMs. iv) Results show that state-of-the-art VLMs achieve near 0% accuracy on SpookyBench, while humans achieve over 98% accuracy; finetuning improved models negligibly. v) The principal implication is that current VLMs over-rely on spatial features and lack architectural mechanisms for processing purely temporal information, indicating the need for novel architectures or training paradigms to decouple spatial dependencies.  |
| Don't Look Only Once: Towards Multimodal Interactive Reasoning with
  Selective Visual Revisitation (Read more on [arXiv](https://arxiv.org/abs/2505.18842) or [HuggingFace](https://huggingface.co/papers/2505.18842))| Min Soo Kim, Jaeyoung Lee, Jiwan Chung, siyeolkim, kjunh | v1 is introduced, enabling multimodal reasoning via dynamic visual revisitation in MLLMs. The paper addresses the limitation of current MLLMs that only consume visual input once. The research question is how to effectively enable MLLMs to revisit images during reasoning. The methodology involves a point-and-copy mechanism and a newly constructed dataset, v1g, of 300K multimodal reasoning traces with visual grounding annotations. Experiments show v1 consistently improves performance on multimodal mathematical reasoning benchmarks, such as a 68.6% mini average on MathVista, MathVision, and MathVerse. The principal implication is that dynamic visual access significantly enhances grounded multimodal reasoning, suggesting a promising direction for AI development. |
| Large Language Models for Data Synthesis (Read more on [arXiv](https://arxiv.org/abs/2505.14752) or [HuggingFace](https://huggingface.co/papers/2505.14752))| Lijun Sun, Menglin Kong, HYTYH | LLMSYNTHOR is introduced as a framework for synthesizing data using large language models (LLMs) while ensuring statistical fidelity. The research aims to improve LLM-based data synthesis by addressing limitations in efficiency, context limits, and statistical alignment. LLMSYNTHOR uses LLMs as nonparametric copula simulators, employs LLM Proposal Sampling for efficient grounded distributions, and utilizes an iterative synthesis loop to minimize summary statistic discrepancies between real and synthetic data. Evaluations across e-commerce, population, and mobility datasets demonstrate high statistical fidelity, utility, and adaptability, including achieving low divergence and gap scores in e-commerce transaction synthesis. LLMSYNTHOR provides AI practitioners with a robust tool for generating high-quality synthetic datasets across diverse domains, improving training data availability and reducing reliance on real-world datasets.  |
| HardTests: Synthesizing High-Quality Test Cases for LLM Coding (Read more on [arXiv](https://arxiv.org/abs/2505.24098) or [HuggingFace](https://huggingface.co/papers/2505.24098))| Jiabao Ji, Kexun Zhang, Yee Man Choi, Zhongmou He, JuntingZhou | i) This paper introduces HARDTESTGEN, a pipeline for synthesizing high-quality test cases for large language model (LLM) coding. ii) The research aims to address the lack of reliable verifiers in LLM coding by generating difficult-to-synthesize edge cases. iii) The methodology involves using LLMs to generate test generator programs and filtering test cases using human-written oracle programs. iv) The study curates a comprehensive competitive programming dataset, HARDTESTS, demonstrating 11.3 percentage points higher precision and 17.5 percentage points higher recall compared to existing tests when evaluating LLM-generated code. v) The key implication is the provision of a more reliable verification mechanism, essential for post-training techniques like reinforcement learning and self-distillation in LLM coding.  |
| ViStoryBench: Comprehensive Benchmark Suite for Story Visualization (Read more on [arXiv](https://arxiv.org/abs/2505.24862) or [HuggingFace](https://huggingface.co/papers/2505.24862))| Yaoqi Hu, Jingwei Wu, Ailin Huang, Cailin Zhuang, wchengad | i) The paper introduces ViStoryBench, a comprehensive benchmark for story visualization. ii) The research aims to provide a standardized evaluation framework to enhance story visualization model performance in real-world scenarios by assessing different plots, artistic styles, and character consistency. iii) The methodology involves collecting a diverse dataset of 80 story segments with 344 roles and developing 12 automated evaluation metrics, including Character Identification Similarity (CIDS), prompt adherence, and style consistency. iv) Evaluation of over twenty methods revealed, through user studies, that UNO achieved top ratings for environment consistency (82.0), while Doubao achieved top ratings for character identification consistency (92.6). v) ViStoryBench enables AI practitioners to thoroughly evaluate strengths and weaknesses of story visualization models, fostering targeted improvements in areas like character portrayal and visual coherence.  |
| Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and
  Benchmarking Multimodal LLM Agents (Read more on [arXiv](https://arxiv.org/abs/2505.24878) or [HuggingFace](https://huggingface.co/papers/2505.24878))| Xiaohan Zhao, Jiacheng Liu, Zhaoyi Li, Yaxin Luo, jiachengcui888 | Open CaptchaWorld is introduced as a novel web-based benchmark for evaluating multimodal large language model (MLLM) agents' ability to solve interactive CAPTCHA puzzles. The research aims to address the lack of benchmarks testing MLLMs in interactive, multi-step reasoning scenarios mimicking real-world web browsing. The methodology involves curating a dataset of 225 CAPTCHAs across 20 types and introducing a new metric called CAPTCHA Reasoning Depth to quantify task complexity. Experiments revealed that state-of-the-art MLLM agents achieve a maximum success rate of 40.0% (Browser-Use Openai-03), significantly lower than the 93.3% achieved by humans, highlighting their limitations in visual reasoning and interaction. Open CaptchaWorld provides AI practitioners with a valuable diagnostic tool to identify weaknesses in current multimodal agents and guide the development of more robust reasoning systems.  |
| Vision Language Models are Biased (Read more on [arXiv](https://arxiv.org/abs/2505.23941) or [HuggingFace](https://huggingface.co/papers/2505.23941))| Vy Tuong Dang, Khai-Nguyen Nguyen, An Vo, knguyennguyen, taesiri | i) This work investigates biases in vision language models (VLMs) on objective visual tasks. ii) The research question explores how prior knowledge impacts VLMs' accuracy on standard object counting, identification, and low-level vision tasks. iii) The methodology employs an automated framework, VLMBias, using image editing and text-to-image generation to create counterfactual images of well-known subjects and evaluating VLM performance on these images. iv) The primary result indicates that state-of-the-art VLMs are strongly biased, achieving only 17.05% accuracy in counting tasks across seven diverse domains, and inserting the subject name into counterfactual image further decreases the VLM accuracy by -2 to -6 percentage points. v) The principal implication for AI practitioners is the need for more robust bias mitigation strategies in VLMs to improve accuracy on tasks requiring visual analysis, suggesting that relying less on memorized knowledge over visual detail can reduce the biases.  |
| CLaSp: In-Context Layer Skip for Self-Speculative Decoding (Read more on [arXiv](https://arxiv.org/abs/2505.24196) or [HuggingFace](https://huggingface.co/papers/2505.24196))| Ziqiang Liu, Lu Wang, Huiming Wang, Renke Shan, Longze Chen | i) CLaSp introduces a novel layer-skipping method for self-speculative decoding to accelerate large language model (LLM) inference without additional training. ii) The research aims to reduce the computational cost of LLM decoding by dynamically adjusting layer sparsity based on the input context. iii) CLaSp uses a dynamic programming algorithm leveraging the complete hidden states from the last verification stage to optimize layer skipping in real-time. iv) Experiments on the LLaMA3 series demonstrate CLaSp achieves a 1.3x to 1.7x speedup compared to autoregressive decoding while preserving the original distribution of generated text. v) CLaSp offers AI practitioners a plug-and-play technique to improve LLM inference efficiency and speed without retraining, potentially simplifying deployment across various models and tasks.  |
| CoDA: Coordinated Diffusion Noise Optimization for Whole-Body
  Manipulation of Articulated Objects (Read more on [arXiv](https://arxiv.org/abs/2505.21437) or [HuggingFace](https://huggingface.co/papers/2505.21437))| Taku Komura, Zhiyang Dou, Zhi Cen, Huaijin Pi | i) The paper introduces CoDA, a novel coordinated diffusion noise optimization framework for synthesizing whole-body manipulation of articulated objects. ii) The primary objective is to generate realistic, physically plausible human-object interaction sequences involving coordinated body, hand, and articulated object motion. iii) The method employs noise-space optimization over three specialized diffusion models for the body, left hand, and right hand, each trained on its own motion dataset, utilizing a basis point set (BPS) representation to encode hand-object spatial relationships. iv) The method achieves state-of-the-art performance on the ARCTIC dataset, with a user study indicating a best motion realism rate of 88.7% and best physical plausibility rate of 87.3%, and the GRAB datasets outperforming existing approaches in motion quality and physical plausibility, as well as enabling capabilities such as object pose control and simultaneous locomotion and manipulation. v) CoDA provides AI practitioners with a new framework for generating coordinated whole-body manipulation motions, improving the realism and plausibility of simulated human interactions, particularly in virtual reality, character animation, and robotics applications.  |
| UniGeo: Taming Video Diffusion for Unified Consistent Geometry
  Estimation (Read more on [arXiv](https://arxiv.org/abs/2505.24521) or [HuggingFace](https://huggingface.co/papers/2505.24521))| Yuan-Chen Guo, Yi-Hua Huang, Zehuan Huang, Xin Yu, Yang-Tian Sun | i) UniGeo leverages video diffusion models for consistent 3D geometry estimation from multi-view images or video sequences. ii) The primary objective is to achieve consistent geometric property estimation across video frames by exploiting inter-frame correspondences inherent in video diffusion models. iii) The methodology involves representing geometric attributes in a global coordinate system, utilizing a shared positional encoding strategy for RGB conditioning, and a multi-task learning approach. iv) Experiments on the ScanNet++ dataset show that UniGeo achieves state-of-the-art results in both normal and radius estimation. v) UniGeo provides AI practitioners with a method for generating consistent 3D geometry from video, improving downstream tasks like 3D reconstruction without requiring camera information.  |
| MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs (Read more on [arXiv](https://arxiv.org/abs/2505.24858) or [HuggingFace](https://huggingface.co/papers/2505.24858))| Tim G. J. Rudner, Idan Szpektor, Avi Caciularu, Gal Yona, Gabrielle Kaili-May Liu | i) MetaFaith benchmarks and improves faithful confidence calibration in LLMs, addressing the misalignment between intrinsic uncertainty and linguistic expression. ii) The research aims to systematically study and improve LLMs' ability to express uncertainty linguistically in alignment with their internal confidence. iii) The methodology involves benchmarking LLMs across diverse models, datasets, and uncertainty elicitation prompts, followed by introducing MetaFaith, a metacognitive prompting approach for calibration. iv) Results show that MetaFaith achieves up to 61% improvement in faithfulness and an 83% win rate over original generations as judged by humans. v) The principal implication is that MetaFaith offers a practical inference-time method for AI practitioners to enhance the reliability and trustworthiness of LLMs by improving their uncertainty communication.  |
| EasyText: Controllable Diffusion Transformer for Multilingual Text
  Rendering (Read more on [arXiv](https://arxiv.org/abs/2505.24417) or [HuggingFace](https://huggingface.co/papers/2505.24417))| Yiren Song, Haifa Wang, Jailing Liu, Yuxuan Zhang, Runnan Lu | i) The paper introduces EasyText, a Diffusion Transformer (DiT) based framework for controllable multilingual text rendering. ii) The main objective is to enable high-quality, controllable text rendering across multiple languages, a challenging task for current diffusion models. iii) The methodology employs character positioning encoding and position encoding interpolation techniques, along with a two-stage training strategy involving large-scale pretraining and fine-tuning. iv) Experiments demonstrate the effectiveness of EasyText, with the fine-tuned model exhibiting an OCR accuracy of 88.72% and improved CLIPScore, suggesting enhanced visual-text alignment. v) The framework allows AI practitioners to accurately render multilingual text in images and manipulate the layout in layout-free or position-controlled manners, demonstrating the generation capability on unfamiliar and unseen characters.  |
| Fork-Merge Decoding: Enhancing Multimodal Understanding in Audio-Visual
  Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.20873) or [HuggingFace](https://huggingface.co/papers/2505.20873))| Joon Son Chung, Jongmin Choi, Youngjoon Jang, Chae0 | Fork-Merge Decoding (FMD) enhances balanced multimodal understanding in audio-visual large language models by addressing modality bias. The research objective is to mitigate modality bias in AV-LLMs without additional training. FMD first performs modality-specific reasoning by processing audio-only and video-only inputs through initial decoder layers and then merges representations for joint reasoning in subsequent layers. Evaluated on VideoLLaMA2 and video-SALMONN with AVQA, MUSIC-AVQA, and AVHBench datasets, FMD consistently improved performance, with a demonstration of the improvement of AVQA from 82.46±0.02 to 82.74±0.05. FMD offers AI practitioners a training-free inference strategy to improve multimodal understanding in AV-LLMs.  |
| Harnessing Negative Signals: Reinforcement Distillation from Teacher
  Data for LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.24850) or [HuggingFace](https://huggingface.co/papers/2505.24850))| Wei Chu, Weidi Xu, Jiangxuan Long, Cheng Peng, Tim-Xu | i) The paper introduces Reinforcement Distillation (REDI), a two-stage offline training framework for enhancing LLM reasoning by leveraging both positive and negative distilled reasoning traces. ii) The research addresses the question of how to effectively use both positive and negative distilled reasoning traces to maximize LLM reasoning performance in an offline setting. iii) REDI employs supervised fine-tuning on positive traces followed by refinement with an asymmetric, reference-free objective that incorporates negative traces. iv) Experiments show that the Qwen-REDI-1.5B model achieves 83.1% on MATH-500 (pass@1) with 131k examples, surpassing DeepSeek-R1-Distill-Qwen-1.5B trained on 800k proprietary data. v) The principal implication for AI practitioners is that REDI offers a more data-efficient approach to distilling complex reasoning abilities into smaller LLMs by effectively utilizing previously discarded negative examples.  |
| Large Language Models are Locally Linear Mappings (Read more on [arXiv](https://arxiv.org/abs/2505.24293) or [HuggingFace](https://huggingface.co/papers/2505.24293))| jamesgolden1 | i) The paper demonstrates that inference operations of open-weight large language models (LLMs) can be mapped to exactly equivalent linear systems for a given input sequence. ii) The main research objective is to determine if and how LLMs, despite their global nonlinearity, exhibit local linearity that can be exploited for understanding their internal representations. iii) The methodology involves strategically altering gradient computations with respect to an input sequence to produce a detached Jacobian, approximating the forward prediction as a linear system, followed by singular value decomposition (SVD) of this Jacobian. iv) The primary result is that the open-weight LLMs can operate in extremely low-dimensional subspaces, with singular vectors decoding to concepts related to the most-likely output token with a relative error of 10^-6 for float32. v) The principal implication for AI practitioners is that LLMs' internal representations can be interpreted through nearly-exact locally linear decompositions, potentially providing insights into semantic structures within the next-token prediction process.  |
| Point-MoE: Towards Cross-Domain Generalization in 3D Semantic
  Segmentation via Mixture-of-Experts (Read more on [arXiv](https://arxiv.org/abs/2505.23926) or [HuggingFace](https://huggingface.co/papers/2505.23926))| Zezhou Cheng, Aruni RoyChowdhury, Wentao Zhou, Xuweiyi Chen | i) This paper introduces Point-MoE, a Mixture-of-Experts architecture for cross-domain generalization in 3D semantic segmentation. ii) The research investigates how to enable large-scale, cross-domain generalization in 3D perception, addressing the limitations of standard point cloud backbones when trained on mixed-domain data. iii) Point-MoE replaces feed-forward layers in Point Transformer V3 with MoE layers comprising multiple expert networks and a routing mechanism. iv) Experiments demonstrate that Point-MoE outperforms multi-domain baselines and generalizes better to unseen domains, achieving 69.2% mIoU on S3DIS validation and 70.2% on test split. v) Point-MoE offers a scalable framework for 3D scene understanding, allowing models to adapt across diverse 3D data sources without manual curation or domain supervision, improving efficiency and scalability in multi-domain 3D semantic segmentation tasks.  |
| Harnessing Large Language Models for Scientific Novelty Detection (Read more on [arXiv](https://arxiv.org/abs/2505.24615) or [HuggingFace](https://huggingface.co/papers/2505.24615))| Erik Cambria, Thanh-Son Nguyen, Soujanya Poria, Yan Liu, ZonglinY | i) This paper explores the use of Large Language Models (LLMs) for scientific novelty detection (ND) by introducing two new datasets in marketing and NLP. ii) The main research question is how to effectively leverage LLMs to identify novel research ideas, addressing the limitations of existing methods in capturing the gap between textual similarity and idea conception. iii) The methodology involves constructing ND-tailored benchmark datasets with topological closure and compactness and training a lightweight retriever using LLM-based knowledge distillation to capture conceptual similarity. iv) Experiments show the proposed method consistently outperforms others in idea retrieval and ND tasks, achieving an average improvement of 5.40% and 15.19% compared to the top-performing baseline on the Marketing domain and NLP task, respectively, in the idea retrieval task. v) The principal implication for AI practitioners is that LLMs, when properly harnessed with knowledge distillation and appropriate datasets, can effectively detect novelty in scientific research by capturing idea conception beyond surface-level textual similarity, providing a valuable tool for researchers and engineers in navigating the increasingly vast landscape of scientific literature.  |
| un^2CLIP: Improving CLIP's Visual Detail Capturing Ability via
  Inverting unCLIP (Read more on [arXiv](https://arxiv.org/abs/2505.24517) or [HuggingFace](https://huggingface.co/papers/2505.24517))| Shiguang Shan, Ruibing Hou, Hong Chang, Jiahe Zhao, yinqi | Contrastive Language-Image Pre-training (CLIP) visual detail capturing is improved through inverting unCLIP. The research aims to improve CLIP's ability to capture visual details in images, addressing limitations in dense prediction and vision-centric tasks. A novel approach, un²CLIP, finetunes the CLIP image encoder by inverting a pretrained unCLIP generator, thereby transferring visual knowledge while preserving language alignment. Experiments on the MMVP-VLM benchmark show un²CLIP achieves a best average performance of 32.6 for OpenAI VIT-L-14, significantly outperforming the original CLIP, indicating enhanced detail discrimination. AI practitioners can leverage un²CLIP to improve CLIP models for tasks requiring finer-grained image understanding such as open-vocabulary segmentation and multimodal large language models.  |
| EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic,
  Expressiveness, and Linguistic Challenges Using Model-as-a-Judge (Read more on [arXiv](https://arxiv.org/abs/2505.23009) or [HuggingFace](https://huggingface.co/papers/2505.23009))| Alex Smola, Mu Li, Xingjian Shi, Yuzhi Tang, ruskinmanku | i) EmergentTTS-Eval introduces a benchmark for evaluating TTS models on complex linguistic and prosodic scenarios using an automated model-as-a-judge approach. ii) The research aims to address limitations in existing TTS benchmarks by developing a comprehensive evaluation suite that captures nuanced and semantically complex text. iii) The methodology iteratively extends seed prompts with LLMs to generate diverse test cases and employs a Large Audio Language Model (LALM) as a judge to assess speech quality across multiple dimensions. iv) Evaluation of TTS systems, including 11Labs and OpenAI's 40-mini-TTS, demonstrates the ability to reveal performance differences, showing that the model-as-a-judge approach offers robust assessment and a high correlation with human preferences. v) The primary implication for AI practitioners is the availability of an open-source, automated benchmark that offers a more fine-grained and reproducible evaluation of TTS systems compared to traditional methods, allowing for targeted improvements in specific areas such as expressiveness and pronunciation accuracy.  |
| Enabling Flexible Multi-LLM Integration for Scalable Knowledge
  Aggregation (Read more on [arXiv](https://arxiv.org/abs/2505.23844) or [HuggingFace](https://huggingface.co/papers/2505.23844))| Xin Meng, Yifan Gong, Shiyue Hou, Zheng Zhan, Zhenglun Kong | i) This paper introduces a framework for adaptively aggregating knowledge from multiple large language models (LLMs) into a single, stronger target model. ii) The primary research objective is to create a more stable and scalable knowledge aggregation process that mitigates knowledge interference when integrating diverse LLMs. iii) The proposed methodology involves an adaptive selection network that identifies relevant source LLMs based on their scores, a dynamic weighted fusion strategy, and a feedback-driven loss function. iv) Experimental results demonstrate that the proposed method reduces knowledge interference by up to 50% compared to existing approaches. v) The research implies that adaptive selection and dynamic weighting are effective strategies for mitigating interference and improving scalability in multi-LLM knowledge aggregation for AI practitioners.  |
| DexUMI: Using Human Hand as the Universal Manipulation Interface for
  Dexterous Manipulation (Read more on [arXiv](https://arxiv.org/abs/2505.21864) or [HuggingFace](https://huggingface.co/papers/2505.21864))| Linxi Fan, Zhenjia Xu, Yifan Hou, Han Zhang, mengdaxu | i) The paper introduces DexUMI, a framework that uses human hand demonstrations with a wearable exoskeleton and visual inpainting to transfer dexterous manipulation skills to diverse robot hands. ii) The research aims to minimize the action and observation gaps between human and robot hands to enable effective imitation learning for dexterous manipulation. iii) The methodology involves hardware adaptation via an optimized exoskeleton, software adaptation through robot hand inpainting in demonstration videos, and subsequent imitation learning. iv) DexUMI achieves an average task success rate of 86% on two different dexterous robot hand hardware platforms and demonstrates a 3.2 times greater data collection efficiency compared to teleoperation. v) AI practitioners can utilize DexUMI to efficiently collect training data and learn policies for dexterous robot manipulation across various hardware platforms, thus accelerating the development of robust robotic systems.  |
| Role-Playing Evaluation for Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.13157) or [HuggingFace](https://huggingface.co/papers/2505.13157))| Yvan Peter, Julian Alvarez, Walter Nuninger, yelboudouri | i) The paper introduces RPEval, a novel benchmark for assessing role-playing capabilities in Large Language Models (LLMs). ii) The research aims to provide an automated and reproducible method for evaluating LLMs across emotional understanding, decision-making, moral alignment, and in-character consistency. iii) The methodology involves creating a dataset of character descriptions and scenarios, then evaluating LLM responses using verifiable tests and majority voting on crowd-sourced annotations. iv) Evaluation of GPT-40, Gemini-1.5-Pro, and Llama 3.2 1B reveals that Gemini-1.5-Pro achieves the highest average score of 62.24%, with notable performance in decision-making and moral alignment (73.86%). v) RPEval offers AI practitioners a structured framework for systematically comparing LLMs and prompting strategies, providing actionable insights for instruction tuning and prompt engineering in role-playing applications, but lacks insight into nuanced long-term role-playing attributes.  |
| GATE: General Arabic Text Embedding for Enhanced Semantic Textual
  Similarity with Matryoshka Representation Learning and Hybrid Loss Training (Read more on [arXiv](https://arxiv.org/abs/2505.24581) or [HuggingFace](https://huggingface.co/papers/2505.24581))| Adel Ammar, Yasser Al-Habashi, Serry Sibaee, Anis Koubaa, Omer Nacar | i) The paper introduces GATE, a General Arabic Text Embedding model for enhanced semantic textual similarity (STS). ii) The objective is to create Arabic text embeddings that achieve state-of-the-art performance on STS tasks. iii) The methodology integrates Matryoshka Representation Learning (MRL) and hybrid loss training using Arabic NLI datasets. iv) GATE demonstrates a 20-25% performance improvement on STS benchmarks compared to larger models, including OpenAI, with the Arabic-Triplet-Matryoshka-V2 model achieving an average score of 69.99 on MTEB Arabic benchmarks. v) The principal implication for AI practitioners is the demonstrated effectiveness of MRL and hybrid loss training in creating more efficient and accurate Arabic text embeddings, offering a resource-efficient alternative to large-scale models for STS tasks in Arabic NLP applications.  |
| LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements
  Generation (Read more on [arXiv](https://arxiv.org/abs/2505.23832) or [HuggingFace](https://huggingface.co/papers/2505.23832))| Wonseok Hwang, Jinu Lee, Chaeeun Kim | LegalSearchLM introduces a novel approach to legal case retrieval (LCR) by generating legal elements directly from a query case. The research aims to improve LCR performance by addressing limitations in existing embedding-based and lexical matching methods. It presents LEGAR BENCH, a large-scale Korean LCR benchmark with 411 diverse crime types across 1.2M cases, and a retrieval model, LEGAL SEARCHLM, performs legal element reasoning over the query case. Experiments show LEGAL SEARCHLM outperforms baselines on LEGAR BENCH standard by 6-20% and generalizes better to out-of-domain cases by 15%. LEGAL SEARCHLM’s generation of legal elements and constrained decoding provide AI practitioners with a new state-of-the-art method for improved retrieval performance, particularly in complex, domain-specific tasks such as LCR.  |
| More Thinking, Less Seeing? Assessing Amplified Hallucination in
  Multimodal Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2505.21523) or [HuggingFace](https://huggingface.co/papers/2505.21523))| James Zou, Juncheng Wu, Qingyue Wei, Zhongxing Xu, Chengzhi Liu | i) This paper investigates increased hallucination in multimodal reasoning models due to extended reasoning chains and decreased visual attention. ii) The main objective is to assess and quantify the trade-off between reasoning ability and hallucination in multimodal reasoning models. iii) The methodology includes attention analysis, the introduction of the RH-AUC metric, and the creation of RH-Bench, a diagnostic benchmark. iv) Results show that reasoning-augmented models exhibit a higher hallucination rate than non-reasoning models, and larger models generally display a better balance between reasoning and perception as measured by RH-AUC. v) The study implies that AI practitioners should prioritize evaluation frameworks and training strategies that explicitly account for both reasoning quality and perceptual reliability in multimodal reasoning models to mitigate hallucination.  |
