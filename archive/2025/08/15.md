

## Papers for 2025-08-15

| Title | Authors | Summary |
|-------|---------|---------|
| We-Math 2.0: A Versatile MathBook System for Incentivizing Visual
  Mathematical Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.10433) or [HuggingFace](https://huggingface.co/papers/2508.10433))| Xiaowan Wang, Yanzi Wang, Peiqing Yang, Qiuna Tan, Runqi Qiao | WE-MATH 2.0 is a unified system integrating a hierarchical knowledge base, model-centric datasets, and a reinforcement learning paradigm to enhance the visual mathematical reasoning of Multimodal Large Language Models (MLLMs). The objective is to overcome MLLM deficiencies in complex mathematical reasoning by developing a comprehensive, knowledge-driven system rather than focusing solely on dataset construction or method optimization. The methodology involves creating a five-level "MathBook Knowledge System" with 491 knowledge points, generating "MathBook-Standard" and "MathBook-Pro" datasets using a three-dimensional difficulty space, and training models with "MathBook-RL," a two-stage framework combining cold-start fine-tuning and progressive alignment reinforcement learning. The resulting MathBook-7B model, trained on only 9.8K samples, achieves a 48.7% average score across four standard benchmarks, outperforming its Qwen2.5-VL-7B backbone (42.6%). For AI practitioners, this research demonstrates that structuring training data around a formal knowledge system and applying a curriculum-based RL strategy can yield significant performance gains in specialized reasoning tasks using substantially less data, offering an efficient alternative to training on massive, unstructured datasets. |
| NextStep-1: Toward Autoregressive Image Generation with Continuous
  Tokens at Scale (Read more on [arXiv](https://arxiv.org/abs/2508.10711) or [HuggingFace](https://huggingface.co/papers/2508.10711))| Quan Sun, Jingwei Wu, Guopeng Li, Chunrui Han, NextStep Team | NextStep-1 is a 14B parameter autoregressive model that generates high-fidelity images by directly predicting a sequence of continuous, rather than discrete, image tokens. The primary objective is to close the performance gap between autoregressive and diffusion-based text-to-image models by avoiding the quantization loss associated with vector quantization (VQ). Its methodology combines a large causal transformer for next-token prediction with a lightweight (157M) flow matching head that samples continuous image patches from noise, conditioned on the transformer's output. The model achieves state-of-the-art performance for an autoregressive architecture, scoring 85.28 on DPG-Bench, which evaluates complex, multi-object compositional fidelity. For AI practitioners, the key implication is that the stability and performance of continuous-token AR models are critically dependent on the image tokenizer's design, specifically its use of channel-wise normalization and noise regularization to create a well-conditioned latent space that enables high-guidance generation without artifacts. |
| ToonComposer: Streamlining Cartoon Production with Generative
  Post-Keyframing (Read more on [arXiv](https://arxiv.org/abs/2508.10881) or [HuggingFace](https://huggingface.co/papers/2508.10881))| Xiaoyu Li, Yaowei Li, Zhaoyang Zhang, Guangzhi Wang, Lingen Li | ToonComposer is a DiT-based generative model that unifies cartoon inbetweening and colorization into a single post-keyframing stage using sparse keyframe sketches. The primary objective is to develop a unified model that automates cartoon production from sparse inputs, overcoming the error accumulation and high labor costs of separate inbetweening and colorization stages. The methodology is based on a Diffusion Transformer (DiT) video foundation model, enhanced with a sparse sketch injection mechanism for precise temporal control and a novel Spatial Low-Rank Adapter (SLRA) to adapt the model's spatial behavior to the cartoon domain while preserving its temporal priors. On a synthetic benchmark, ToonComposer significantly outperformed prior methods, achieving a DISTS score of 0.0926 compared to the next-best score of 0.5461 from AniDoc; in human evaluations, it was preferred for aesthetic quality in 70.99% of cases. The principal implication for AI practitioners is that the SLRA method provides a targeted adaptation technique for video foundation models that selectively modifies spatial representations while leaving temporal dynamics intact, demonstrating a more effective approach than generic adapters for tasks requiring preservation of motion priors. |
| UI-Venus Technical Report: Building High-performance UI Agents with RFT (Read more on [arXiv](https://arxiv.org/abs/2508.10833) or [HuggingFace](https://huggingface.co/papers/2508.10833))| Shuheng Shen, Xingran Zhou, Zhenyu Xu, Zhengwen Zeng, Zhangxuan Gu | UI-Venus is a native UI agent that achieves state-of-the-art (SOTA) performance on UI grounding and navigation tasks using only screenshots as input. The primary objective is to build a high-performance UI agent by applying Reinforcement Finetune (RFT) to a multimodal large language model, demonstrating its superiority over traditional Supervised Fine-Tuning (SFT). The methodology involves using the Group Relative Policy Optimization (GRPO) algorithm for RFT on the Qwen2.5-VL model, coupled with comprehensive data cleaning strategies and a novel "Self-Evolving Trajectory History Alignment & Sparse Action Enhancement" framework for navigation. The 72B variant of UI-Venus achieves a 65.9% success rate on the AndroidWorld navigation benchmark and 95.3% / 61.9% accuracy on the Screenspot-V2 / Pro grounding benchmarks, respectively. For AI practitioners, this work validates that RFT with high-quality curated data and self-evolving frameworks is a potent strategy for developing SOTA UI agents, particularly for complex, discriminative tasks where SFT is less effective. |
| PRELUDE: A Benchmark Designed to Require Global Comprehension and
  Reasoning over Long Contexts (Read more on [arXiv](https://arxiv.org/abs/2508.09848) or [HuggingFace](https://huggingface.co/papers/2508.09848))| Rui Lu, Tong Li, Chulun Zhou, Tsz Ting Chung, Mo Yu | This paper introduces PRELUDE, a benchmark for evaluating long-context reasoning in LLMs by assessing the consistency of character prequels with canonical book narratives. The main objective is to create a benchmark that requires global comprehension and deep, multi-step reasoning, addressing key shortcuts like memorization and summarization present in prior benchmarks. The methodology involves creating a dataset of 795 instances where LLMs must classify a generated character prequel as "consistent" or "contradict" with an entire book; evaluations are conducted using few-shot ICL, Retrieval-Augmented Generation (RAG), and in-domain training on state-of-the-art LLMs. The primary result demonstrates a significant performance deficit in current models, with the best-performing LLM lagging behind human performance by over 15% in F1 score, and a further human study revealing an over 30% gap in reasoning accuracy even for correctly answered instances. The principal implication for AI practitioners is that current long-context evaluation metrics focusing on answer accuracy can be misleading, as models often achieve correct results through flawed reasoning; this indicates that advanced techniques like RAG do not fully resolve fundamental limitations in deep, global reasoning, necessitating a shift in focus towards improving the intrinsic inferential capabilities of models. |
| STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer (Read more on [arXiv](https://arxiv.org/abs/2508.10893) or [HuggingFace](https://huggingface.co/papers/2508.10893))| Honghua Chen, Shangchen Zhou, Fangzhou Hong, Yihang Luo, Yushi Lan | STREAM3R is a decoder-only causal Transformer framework for scalable, sequential 3D reconstruction from streaming images. The main objective is to perform efficient, online, and incremental 3D reconstruction that scales to long image sequences, avoiding the computational cost of global optimization and the limitations of RNN-based memory. The methodology reformulates 3D reconstruction as a sequential registration task, where a causal Transformer processes incoming frames by attending to a cache of features from all previously observed frames, inspired by modern LLM architectures. The primary result is superior performance on standard benchmarks; on the 7-Scenes dataset, STREAM3R achieves a mean reconstruction accuracy of 0.122, outperforming prior streaming and optimization-based methods. For AI practitioners, the principal implication is that LLM-style causal attention and training infrastructure can be directly adapted for efficient, real-time 3D perception from streaming video, offering a scalable approach for applications like robotics and autonomous systems. |
| Pass@k Training for Adaptively Balancing Exploration and Exploitation of
  Large Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2508.10751) or [HuggingFace](https://huggingface.co/papers/2508.10751))| Qinghao Ye, Yue Ling, Youbin Wu, Xiaobo Qin, Zhipeng Chen | This paper introduces Pass@k Training, a reinforcement learning with verifiable rewards (RLVR) method using an analytical advantage function to enhance LLM exploration and improve final reasoning performance. The research objective is to address the poor exploration-exploitation balance in standard Pass@1-based RLVR, which leads to models becoming trapped in local optima, by using Pass@k as a reward signal to promote more diverse solution generation. The key methodology is a novel training paradigm that uses the Pass@k metric as the reward, for which the authors derive a computationally efficient, closed-form analytical solution for the advantage function, eliminating the variance and overhead of sampling-based approaches. The primary result is that a two-stage process—Pass@k Training followed by Pass@1 Training—significantly boosts performance; on the Enigmata benchmark, this method improved a Qwen2.5-7B model's overall Pass@1 score from a baseline of 4.7% to 30.8%, outperforming Claude-3.7-Sonnet (22.7%). The principal implication for AI practitioners is that they can train stronger reasoning models by first employing Pass@k Training to broaden a model's exploration capabilities and then fine-tuning with Pass@1 Training to distill those gains into superior final accuracy. |
| HumanSense: From Multimodal Perception to Empathetic Context-Aware
  Responses through Reasoning MLLMs (Read more on [arXiv](https://arxiv.org/abs/2508.10576) or [HuggingFace](https://huggingface.co/papers/2508.10576))| Yi Yuan, Tianqi Li, Yabing Wang, Ruobing Zheng, Zheng Qin | The paper introduces HumanSense, a comprehensive benchmark for evaluating the human-centered perception and interaction capabilities of Multimodal Large Language Models (MLLMs). The main objective is to systematically assess and improve MLLM capabilities in understanding complex human intentions and generating empathetic, context-aware responses, addressing the lack of fine-grained evaluation frameworks for such scenarios. The authors created a 15-task, four-tier benchmark and applied a multi-stage, omni-modal reinforcement learning strategy to enhance a model's reasoning capabilities across visual, auditory, and textual inputs. Evaluation results reveal a significant performance gap between the human baseline (87.5% accuracy) and top MLLMs, though the authors' reinforcement learning method improved accuracy on the complex Psychological Chat task from 0.399 to 0.619. The principal implication for AI practitioners is that high-level reasoning is the primary bottleneck for MLLMs in human-centered interaction, and performance can be substantially improved by leveraging omni-modal inputs and employing reasoning-focused training or prompt engineering. |
| A Survey on Diffusion Language Models (Read more on [arXiv](https://arxiv.org/abs/2508.10875) or [HuggingFace](https://huggingface.co/papers/2508.10875))| Zhiqiang Shen, Bowei Guo, Mingda Chen, Tianyi Li | This paper provides a comprehensive survey of Diffusion Language Models (DLMs), detailing their principles, training, inference, and applications as a parallelizable alternative to autoregressive models. Its objective is to establish a systematic taxonomy of the DLM landscape, reviewing foundational concepts, state-of-the-art models, and multimodal extensions. The key methodology is a structured literature review that classifies DLMs by their diffusion space (continuous vs. discrete), training strategies (e.g., pre-training, RL alignment), and inference optimizations (e.g., parallel decoding). Primary results show that scaled discrete DLMs achieve performance competitive with similarly-sized AR models, and post-training methods like DCoLT can significantly boost reasoning capabilities, yielding a +9.8% gain on the GSM8K benchmark. The principal implication for practitioners is that DLMs are a compelling alternative for high-throughput, low-latency generation tasks, warranting consideration in system design where parallel inference is critical. |
| From Black Box to Transparency: Enhancing Automated Interpreting
  Assessment with Explainable AI in College Classrooms (Read more on [arXiv](https://arxiv.org/abs/2508.10860) or [HuggingFace](https://huggingface.co/papers/2508.10860))| Ziyin Zhang, Zhaokun Jiang | This paper presents an explainable AI framework for automated, multi-dimensional assessment of English-Chinese interpreting performance. The research aims to overcome data scarcity and model opacity in interpreting assessment by developing a transparent system that can predict quality across fidelity, fluency, and language use dimensions. The methodology combines feature engineering, data augmentation using a Variational Autoencoder (VAE) to expand the dataset from 117 to 500 samples, and post-hoc explanation using Shapley Additive exPlanations (SHAP) on XGBoost and Random Forest models. The primary result is that VAE-based augmentation significantly improved model performance, and SHAP analysis identified key predictive features; for fidelity, the neural metric BLEURT was the most important predictor with a mean SHAP value of 0.32, while for fluency, pause-related features were most influential. The principal implication for AI practitioners is that combining generative data augmentation (VAE) with post-hoc explainability (SHAP) offers a powerful pipeline for developing accurate and trustworthy models in data-scarce, high-stakes domains, transforming predictive systems into actionable diagnostic tools. |
| Processing and acquisition traces in visual encoders: What does CLIP
  know about your camera? (Read more on [arXiv](https://arxiv.org/abs/2508.10637) or [HuggingFace](https://huggingface.co/papers/2508.10637))| Giorgos Tolias, Yuta Nakashima, Giorgos Kordopatis-Zilos, Vladan Stojnić, Ryan Ramos | This paper demonstrates that visual encoders, particularly Contrastive Vision-Language (CVL) models, systematically encode subtle image processing and acquisition metadata, which can disrupt semantic understanding. The research aims to determine if these metadata "traces" are embedded in visual representations and how they impact downstream semantic tasks. The methodology involves training linear classifiers to predict metadata labels from frozen embeddings of 47 visual encoders and evaluating performance on retrieval and classification tasks where metadata and semantic labels are deliberately correlated or anti-correlated. The primary result is that these traces are strongly encoded, especially in CVL models which can predict processing parameters like JPEG compression with over 80% accuracy, and this can overshadow semantic content. The principal implication for AI practitioners is that foundational models may exhibit biases towards non-semantic artifacts, leading to unreliable performance and spurious correlations in real-world applications where data acquisition and processing pipelines vary. |
| When Explainability Meets Privacy: An Investigation at the Intersection
  of Post-hoc Explainability and Differential Privacy in the Context of Natural
  Language Processing (Read more on [arXiv](https://arxiv.org/abs/2508.10482) or [HuggingFace](https://huggingface.co/papers/2508.10482))| Gjergji Kasneci, Florian Matthes, Ege Erdogan, Stephen Meisenbacher, Mahdi Dhaini | This paper empirically investigates the trade-off between post-hoc explainability and differentially private (DP) text rewriting in Natural Language Processing. The central objective is to quantify the impact of applying local DP text rewriting on the post-hoc explainability faithfulness of fine-tuned language models. The methodology involves applying three DP text rewriting methods (TEM, DP-PROMPT, DP-BART) to three text classification datasets, fine-tuning five encoder-only PLMs, and evaluating four feature attribution methods using a composite score that balances model utility (F1) and explanation faithfulness (AOPC metrics). A primary result is that smaller base models consistently outperform larger models under DP constraints, with the composite score for large models dropping by as much as -0.286 compared to base models on the SST2 dataset. The principal implication for AI practitioners is that for privacy-sensitive applications requiring explainability, using the smallest acceptable pretrained model is preferable, as larger models exhibit a more significant degradation in both performance and explanation quality. |
