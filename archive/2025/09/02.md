

## Papers for 2025-09-02

| Title | Authors | Summary |
|-------|---------|---------|
| PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.21104) or [HuggingFace](https://huggingface.co/papers/2508.21104))| Yuewei Zhang, Penghong Zhao, Wenfeng Feng, Chuzhan, Nothing2Say | The paper introduces PVPO, a critic-free reinforcement learning algorithm that improves policy optimization for agentic reasoning using a pre-estimated, static value baseline. Its objective is to mitigate the local optima and high computational cost of group policy methods by correcting the cumulative bias from intra-group comparisons and reducing reliance on extensive rollouts. The key methodology is to use a fixed reference model to compute a "Static V Estimate," which serves as a stable anchor for advantage calculation (Â = Qdyn - Vsta), combined with a group sampling strategy that filters training data and injects ground-truth trajectories for sparse reward samples. PVPO achieves state-of-the-art performance, outperforming the GRPO baseline by over 5 percentage points in average accuracy (61.00% vs. 56.78%) on multi-step retrieval tasks. For AI practitioners, PVPO offers a resource-efficient training paradigm, enabling the development of more stable and performant agentic models with significantly reduced computational overhead by achieving 97% of a baseline's performance with less than 40% of the cost. |
| T2R-bench: A Benchmark for Generating Article-Level Reports from Real
  World Industrial Tables (Read more on [arXiv](https://arxiv.org/abs/2508.19813) or [HuggingFace](https://huggingface.co/papers/2508.19813))| Yu Zhao, Sishi Xiong, Kaiwen Wei, Changzai Pan, Jie Zhang | The paper introduces T2R-bench, a bilingual benchmark for evaluating Large Language Models on the industrial task of generating article-level reports from complex, real-world tabular data. The primary objective is to assess an LLM's ability to transform diverse and complex industrial tables into comprehensive, accurate reports, addressing a gap between academic benchmarks and practical needs. The methodology involves constructing the T2R-bench dataset from 457 industrial tables and proposing a tripartite evaluation framework comprising a Numerical Accuracy Criterion (NAC), an Information Coverage Criterion (ICC), and a General Evaluation Criterion (GEC). Experiments on 25 LLMs reveal that current models struggle significantly, with the top-performing model, Deepseek-R1, achieving an overall score of only 62.71%. The principal implication for AI practitioners is that current LLMs have fundamental limitations in reasoning over large-scale industrial tabular data for report generation, highlighting a critical need for developing specialized models for this application. |
| No Label Left Behind: A Unified Surface Defect Detection Model for all
  Supervision Regimes (Read more on [arXiv](https://arxiv.org/abs/2508.19060) or [HuggingFace](https://huggingface.co/papers/2508.19060))| Danijel Skočaj, MaticFuc, blaz-r | This paper presents SuperSimpleNet, a unified discriminative model for surface defect detection designed to operate across unsupervised, weakly supervised, mixed, and fully supervised settings. The objective is to create a single, efficient model that can leverage all available data annotations, regardless of their supervision level, to address diverse real-world industrial inspection scenarios. The methodology enhances the SimpleNet architecture by incorporating a novel latent-space synthetic anomaly generation process using a binarized Perlin noise mask, a dual-branch architecture with an improved classification head, and an adaptive learning procedure. SuperSimpleNet achieves state-of-the-art results across all regimes, including a 98.0% AUROC on the fully supervised SensumSODF dataset, while maintaining a 9.5 ms inference time. The principal implication for AI practitioners is the availability of a single, high-performance model that unifies diverse supervision paradigms, enabling the effective use of heterogeneous and incomplete datasets common in industrial applications without needing separate models for each labeling condition. |
| UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via
  HUMAIN Chat (Read more on [arXiv](https://arxiv.org/abs/2508.17378) or [HuggingFace](https://huggingface.co/papers/2508.17378))| Omartificial-Intelligence-Space | This paper presents a UI-level evaluation of the Arabic-centric LLM ALLaM 34B via its deployment in the HUMAIN Chat interface. The primary objective was to assess the model's performance across diverse linguistic and functional tasks, including modern standard Arabic (MSA), five regional dialects, code-switching, and adversarial safety. The methodology involved generating 115 responses from a 23-prompt pack, which were then scored across five metrics by three frontier LLM judges: GPT-5, Gemini 2.5 Pro, and Claude Sonnet-4. Key results show high performance in code-switching and generation tasks (both mean score 4.92/5) and robust safety (4.54/5), but significantly weaker performance in certain dialects, such as Levantine and Moroccan (both 2.7/5 overall). For AI practitioners, this study's principal implication is that developing culturally aligned Arabic models requires targeted collection of high-quality dialectal corpora to address performance imbalances and prevent reversion to MSA, thereby improving true dialectal fidelity. |
| From reactive to cognitive: brain-inspired spatial intelligence for
  embodied agents (Read more on [arXiv](https://arxiv.org/abs/2508.17198) or [HuggingFace](https://huggingface.co/papers/2508.17198))| Songming Liu, Qihui Zhu, Caixin Kang, Liyuan Wang, Shouwei Ruan | The paper presents BSC-Nav, a brain-inspired framework that equips embodied agents with structured spatial memory to transition from reactive to cognitive navigation. The main objective is to develop a unified framework that constructs and leverages structured spatial memory—comprising landmarks, route knowledge, and survey knowledge—to enhance the generalization and long-horizon reasoning of embodied agents in complex environments. BSC-Nav integrates three modules: a landmark memory for salient cues, a cognitive map that voxelizes egocentric trajectories into allocentric survey knowledge using a surprise-driven update strategy, and a working memory that uses MLLMs for hierarchical retrieval to align semantic goals with spatial actions. The framework achieves state-of-the-art performance across diverse navigation tasks; in Object-Goal Navigation on the HM3D dataset, it attains a 78.5% Success Rate, surpassing the prior state-of-the-art method UniGoal by 24.0%. The principal implication for AI practitioners is that this work provides a modular architecture for integrating persistent, structured spatial memory with foundation models, offering a practical blueprint for developing more cognitively capable embodied AI that can overcome the limitations of reactive, stateless agents in real-world tasks. |
| How Can Input Reformulation Improve Tool Usage Accuracy in a Complex
  Dynamic Environment? A Study on τ-bench (Read more on [arXiv](https://arxiv.org/abs/2508.20931) or [HuggingFace](https://huggingface.co/papers/2508.20931))| Jayanth Srinivasa, Mutsumi Nakamura, Satyam Raj, Amir Saeidi, Venkatesh Mishra | i) This paper proposes the Input-Reformulation Multi-Agent (IRMA) framework, which improves the tool-usage accuracy of LLM agents in dynamic, multi-turn environments. ii) The objective is to mitigate LLM agent failures in reasoning, policy adherence, and information extraction by systematically reformulating the input provided to the agent before it acts. iii) The methodology involves a multi-agent system that automatically augments user queries with relevant domain constraints and tool suggestions, creating a structured input for the primary tool-calling agent. iv) The primary result on the τ-bench benchmark is that IRMA significantly outperforms ReAct, Function Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in overall pass@5 scores. v) The principal implication for AI practitioners is that preemptively structuring an agent's input with relevant policies and tool context is a highly effective, loop-free strategy to enhance reliability and policy adherence in complex, stateful tasks, proving more robust than post-hoc correction methods. |
