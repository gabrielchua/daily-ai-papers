

## Papers for 2025-09-05

| Title | Authors | Summary |
|-------|---------|---------|
| From Editor to Dense Geometry Estimator (Read more on [arXiv](https://arxiv.org/abs/2509.04338) or [HuggingFace](https://huggingface.co/papers/2509.04338))| Lang Nie, Rongying Liu, Lei Sun, Chunyu Lin, exander | This paper introduces FE2E, a framework that adapts pre-trained image editing models for high-performance, zero-shot monocular dense geometry estimation. The objective is to demonstrate that image editing models are a more suitable foundation than text-to-image generative models for this task and to develop an effective adaptation protocol. Key methodologies include reformulating the editor's flow matching loss into a "consistent velocity" objective for deterministic prediction, using logarithmic quantization to resolve precision conflicts, and implementing a cost-free joint estimation of depth and normals by repurposing the Diffusion Transformer's (DiT) architecture. FE2E achieves state-of-the-art results, including a 35% performance gain in Absolute Relative error on the ETH3D depth estimation dataset compared to the next-best method, while being trained on 100x less data than competing large-scale models. The principal implication for AI practitioners is that fine-tuning image editing models, which possess stronger inherent structural priors, offers a more data-efficient and performant pathway for dense vision tasks than adapting T2I generative models. |
| Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth (Read more on [arXiv](https://arxiv.org/abs/2509.03867) or [HuggingFace](https://huggingface.co/papers/2509.03867))| Chi-Li Chen, Zi Yan Chang, Chia-Yi Hsiao, Chenghao Xiao, Yang Wang | This research introduces "Drivelology," a linguistic phenomenon of syntactically coherent but pragmatically paradoxical text, and presents the DRIVELHUB benchmark to evaluate LLMs' comprehension of such layered semantics. The primary objective is to assess if LLMs can move beyond surface-level pattern matching to grasp the implicit, non-linear meanings embedded in Drivelological text, which requires deep contextual and cultural inference. The methodology involves evaluating various LLMs on the new multilingual DRIVELHUB dataset across four tasks: binary classification (Detection), multi-label classification (Tagging), generation (Narrative Writing), and multiple-choice question answering (Narrative Selection). Key results demonstrate a significant performance deficit in current models, with the top-scoring model on the Hard Narrative Selection task achieving only 26.78% accuracy, exposing a critical failure in complex reasoning. For AI practitioners, this research highlights that statistical fluency is not a reliable proxy for cognitive comprehension, indicating that models for applications requiring nuanced human interaction must be evaluated on benchmarks that specifically test for understanding of multi-layered pragmatic paradox and implicit rhetoric. |
| Towards a Unified View of Large Language Model Post-Training (Read more on [arXiv](https://arxiv.org/abs/2509.04419) or [HuggingFace](https://huggingface.co/papers/2509.04419))| Hongyi Liu, Youbang Sun, Yuxin Zuo, Xingtai Lv, iseesaw | This paper presents a unified framework for LLM post-training, demonstrating that Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT) are instances of a single optimization process. The main objective is to formalize the relationship between online (RL) and offline (SFT) training methods by deriving a common gradient formulation. The authors introduce the Unified Policy Gradient Estimator (UPGE) and propose a practical algorithm, Hybrid Post-Training (HPT), which dynamically switches between SFT and RL objectives based on real-time task performance. HPT demonstrates superior performance over baselines; for instance, using Qwen2.5-Math-7B on the AIME 2024 benchmark, HPT achieved a score of 33.0, a 6.9-point improvement over the LUFFY baseline. For AI practitioners, HPT provides an adaptive method to combine SFT and RL, potentially yielding better model performance without the high cost and tuning complexity of sequential SFT-then-RL pipelines. |
| Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow
  Real Instructions? (Read more on [arXiv](https://arxiv.org/abs/2509.04292) or [HuggingFace](https://huggingface.co/papers/2509.04292))| Yu Fu, Ruijie Miao, Xinping Lei, Qinyan Zhang, zhangysk | This paper introduces Inverse IFEval, a benchmark to evaluate an LLM's ability to follow counter-intuitive instructions that conflict with patterns learned during supervised fine-tuning. The research objective is to measure an LLM's "Counter-intuitive Ability," specifically its capacity to overcome training-induced cognitive inertia and comply with adversarial instructions. The methodology involves a dataset of 1012 Chinese and English questions across eight counter-intuitive categories (e.g., Intentional Textual Flaws, Code without Comments), evaluated via an optimized LLM-as-a-Judge framework. Results show that models struggle significantly, with the fine-tuned Qwen3-235B-A22B-Instruct model's rank dropping from 5th on the conventional IFEval benchmark to 15th on Inverse IFEval. For AI practitioners, the principal implication is that current alignment processes can induce overfitting to narrow patterns, and future efforts must focus on mitigating cognitive inertia to improve instruction-following reliability on out-of-distribution user requests. |
| DeepResearch Arena: The First Exam of LLMs' Research Abilities via
  Seminar-Grounded Tasks (Read more on [arXiv](https://arxiv.org/abs/2509.01396) or [HuggingFace](https://huggingface.co/papers/2509.01396))| Jiaxuan Lu, Meiqi Tu, Junchi Yu, Chen Yang, haiyuanwan | i) This paper introduces DeepResearch Arena, a novel benchmark derived from academic seminar transcripts to evaluate the multi-stage research capabilities of LLMs while minimizing data leakage. ii) The main objective is to create a scalable and authentic benchmark that faithfully evaluates the research abilities of deep research agents by grounding tasks in real-world expert discourse, overcoming the data contamination risks and scalability limitations of existing benchmarks. iii) The methodology involves a Multi-Agent Hierarchical Task Generation (MAHTG) system that automatically extracts research inspirations from seminar transcripts and synthesizes them into over 10,000 research tasks, which are evaluated using a hybrid protocol combining Keypoint-Aligned Evaluation (KAE) for factual grounding and Adaptively-generated Checklist Evaluation (ACE) for higher-order reasoning. iv) The primary results demonstrate substantial performance gaps across current models, with `grok-4` achieving the highest factual coverage on English tasks (83.3% Keypoint Supported Rate), while `o4-mini-deepresearch` attained the highest subjective reasoning score (4.03 ACE score). v) The principal implication for AI practitioners is that DeepResearch Arena provides a robust framework and dataset for benchmarking LLM agents on cognitively demanding, open-ended research tasks, enabling a more accurate assessment of their practical utility for automating complex scientific workflows beyond standard question-answering. |
| Transition Models: Rethinking the Generative Learning Objective (Read more on [arXiv](https://arxiv.org/abs/2509.04394) or [HuggingFace](https://huggingface.co/papers/2509.04394))| Yangguang Li, Xiangyu Yue, Xiaoyu Yue, Yiyuan Zhang, GoodEnough | Transition Models (TiM) introduce a generative paradigm that learns the entire solution manifold of the generative process, enabling high-fidelity synthesis across arbitrary step sizes from a single model. The objective is to resolve the trade-off between the high computational cost of iterative diffusion models and the quality ceiling of efficient few-step generators by creating a unified model effective at any number of function evaluations (NFEs). The key methodology is a novel training objective derived from an exact "State Transition Identity" equation, made scalable by a finite-difference approximation called the Differential Derivation Equation (DDE) that avoids computationally expensive Jacobian-Vector Products and is compatible with distributed training. The 865M parameter TiM achieves a GenEval score of 0.67 at 1-NFE and monotonically improves to 0.83 at 128-NFE, outperforming 12B parameter models like FLUX.1 across all evaluated step counts. For AI practitioners, this eliminates the need for separate models or distillation pipelines for different inference budgets, offering a single, flexible model for applications requiring either real-time generation or maximum-quality rendering. |
| NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware
  Embeddings (Read more on [arXiv](https://arxiv.org/abs/2509.04011) or [HuggingFace](https://huggingface.co/papers/2509.04011))| Oren Glickman, Yoav Goldberg, Uri Katz, Or Shachar | i) This paper presents NER Retriever, a zero-shot framework for ad-hoc Named Entity Retrieval that creates compact, type-aware embeddings from internal Large Language Model representations. ii) The primary objective is to retrieve all text segments mentioning entities of a type defined at query time by mapping both entity mentions and open-ended type descriptions into a shared semantic space for similarity search. iii) The methodology involves extracting value vectors from an intermediate transformer block (layer 17 of LLaMA 3.1 8B) and using a lightweight, contrastively-trained multilayer perceptron to project these representations into a discriminative embedding space. iv) The system significantly outperforms baselines on two of three benchmarks, achieving an R-Precision of 0.32 on the MultiCoNER 2 dataset, more than three times higher than the E5-Mistral dense retrieval model (0.09). v) The principal implication for AI practitioners is that internal LLM representations, specifically mid-layer value vectors, encode fine-grained type information more effectively than standard top-layer embeddings, offering a practical method for building scalable and more accurate schema-free entity retrieval systems. |
| Few-step Flow for 3D Generation via Marginal-Data Transport Distillation (Read more on [arXiv](https://arxiv.org/abs/2509.04406) or [HuggingFace](https://huggingface.co/papers/2509.04406))| Lingxi Xie, Chen Yang, Jiemin Fang, Zanwei Zhou, thewhole | This paper introduces MDT-dist, a novel distillation framework that significantly accelerates flow-based 3D generation by directly learning the marginal-data transport. The research objective is to distill a pretrained, multi-step 3D flow model into a generator capable of producing high-fidelity 3D assets in only one or two sampling steps. The methodology proposes two complementary objectives: Velocity Matching (VM) to stably match velocity fields between student and teacher models, and Velocity Distillation (VD) to perform probability density distillation using these learned velocity fields. Applied to the TRELLIS framework, the method reduces sampling steps from 25 per component to just one, achieving a 9.0x speedup and 0.68s inference latency on an A800 GPU while maintaining high geometric fidelity. For AI practitioners, this framework provides a direct method to drastically reduce the inference cost of complex generative models for 3D assets, enabling their use in time-sensitive applications like interactive content creation. |
| Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding (Read more on [arXiv](https://arxiv.org/abs/2508.20478) or [HuggingFace](https://huggingface.co/papers/2508.20478))| Lionel Ni, Zheng Ge, Tianshui Chen, Yuan Xie | Video-MTR is a reinforced multi-turn reasoning framework that enables MLLMs to iteratively select and comprehend key segments in long videos for improved understanding. The objective is to develop an end-to-end trainable model that overcomes the limitations of static, single-turn reasoning in long-form video understanding by mimicking human-like iterative evidence gathering. The framework employs reinforcement learning (PPO) with a novel gated bi-level reward system, where an MLLM agent is trained to sequentially retrieve relevant video frames, guided by both turn-level frame-relevance rewards (IoU) and a final trajectory-level answer-correctness reward. Video-MTR demonstrates significant performance gains on longer videos, improving accuracy by +6.3% (from 44.7% to 51.0%) over its base model on the Long subset of the VideoMME benchmark. The principal implication for AI practitioners is that for complex, long-duration sequential data tasks, an RL-based multi-turn paradigm with fine-grained intermediate rewards can enhance performance and efficiency over standard supervised fine-tuning, achieving superior results with substantially less training data (8K samples). |
| Durian: Dual Reference-guided Portrait Animation with Attribute Transfer (Read more on [arXiv](https://arxiv.org/abs/2509.04434) or [HuggingFace](https://huggingface.co/papers/2509.04434))| Hanbyul Joo, Byungjun Kim, Hyunsoo Cha | Durian is a zero-shot diffusion-based framework for generating portrait animation videos by transferring facial attributes from a reference image to a target portrait. The main objective is to create a generalizable method for animating a static portrait image while simultaneously transferring diverse, deformable facial attributes from a single, cross-identity reference image, without requiring triplet training data. The key methodology involves a diffusion model with a Dual ReferenceNet architecture that injects spatial features from two masked inputs: an attribute-only reference and an attribute-masked portrait, trained using a self-reconstruction strategy on videos with an attribute-aware mask expansion technique. The framework achieves state-of-the-art performance, attaining an FID score of 38.00, which surpasses the best-performing two-stage baseline combination that scored 57.86. For AI practitioners, this single-stage pipeline enables the development of dynamic virtual try-on and content creation tools that support multi-attribute composition and interpolation from static images in a single forward pass without additional training. |
| Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from
  Vector Drawings (Read more on [arXiv](https://arxiv.org/abs/2508.18733) or [HuggingFace](https://huggingface.co/papers/2508.18733))| Meie Fang, Changmiao Wang, Shichao Lu, Feiwei Qin, 1nnoh | Drawing2CAD presents a sequence-to-sequence Transformer framework for generating parametric 3D CAD models directly from 2D vector engineering drawings. The primary objective is to automate the creation of precise, editable CAD models from vector graphics (SVG), aligning with industrial workflows and avoiding the imprecision of raster-based inputs. The methodology features a dual-decoder architecture that decouples CAD command type and parameter generation, a concatenation-based embedding for input primitives, and a soft target distribution loss function to allow for parameter flexibility. On the authors' newly created CAD-VGDrawing dataset, the model achieved a command accuracy of 82.43% and reduced the invalid model generation ratio to 20.31% using a four-view input. For AI practitioners, this work provides a direct blueprint for developing systems that translate geometrically precise 2D vector drawings into structured, parametric 3D models, enabling automation in engineering design pipelines. |
| Delta Activations: A Representation for Finetuned Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.04442) or [HuggingFace](https://huggingface.co/papers/2509.04442))| Ser-Nam Lim, Mayur Naik, Amish Sethi, OscarXZQ | The paper introduces Delta Activations, a method for representing finetuned LLMs as vector embeddings by measuring shifts in their internal activations relative to a base model. The primary objective is to create a compact, semantically meaningful representation to enable efficient discovery, comparison, and clustering of finetuned models without relying on metadata. The methodology involves computing the difference between a finetuned model's and its base model's last-layer hidden state activations on a fixed set of generic prompts, then averaging these differences to form the final embedding. This method achieves superior domain-based clustering, yielding an average silhouette score of 0.614 across three backbones, significantly outperforming baselines like flattened weights (-0.043) and output embeddings (0.087). For AI practitioners, Delta Activations provide a computationally efficient tool to navigate and organize large model hubs, enabling better model selection, reuse, and merging without access to original training data. |
| False Sense of Security: Why Probing-based Malicious Input Detection
  Fails to Generalize (Read more on [arXiv](https://arxiv.org/abs/2509.03888) or [HuggingFace](https://huggingface.co/papers/2509.03888))| Muhao Chen, Qin Liu, Zeming Wei, Cheng Wang | This research demonstrates that probing-based classifiers for LLM safety fail to generalize by learning superficial linguistic patterns instead of genuine semantic harmfulness. The study's objective is to determine why these classifiers achieve near-perfect in-domain accuracy but collapse on out-of-distribution (OOD) data. The methodology involves controlled experiments evaluating classifiers on "semantically cleaned" datasets, where harmful concepts are replaced with benign ones while preserving the original instructional and syntactic patterns. The primary result is a dramatic performance collapse on this controlled data, with classifier accuracy dropping by 60-90 percentage points, proving their reliance on surface-level cues like instructional patterns and trigger words over semantic content. The principal implication for AI practitioners is that current probing-based safety mechanisms provide a false sense of security; their high in-domain accuracy is not indicative of robust harmfulness detection, and they should not be trusted in production systems without rigorous semantic and OOD evaluation. |
