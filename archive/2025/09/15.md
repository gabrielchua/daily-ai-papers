

## Papers for 2025-09-15

| Title | Authors | Summary |
|-------|---------|---------|
| IntrEx: A Dataset for Modeling Engagement in Educational Conversations (Read more on [arXiv](https://arxiv.org/abs/2509.06652) or [HuggingFace](https://huggingface.co/papers/2509.06652))| Gabriele Pergola, Chiara Gambi, Mahathi Parvatham, XingweiT | This paper introduces IntrEx, a dataset of teacher-student conversations annotated for interestingness to model conversational engagement. The objective is to identify linguistic drivers of engagement and evaluate if Large Language Models (LLMs) can align with human interestingness judgments. The methodology involved collecting sequence-level interestingness ratings from over 100 second-language learners using a comparison-based annotation framework inspired by Reinforcement Learning from Human Feedback (RLHF). The primary result is that 7B/8B parameter models (Mistral-7B and Llama3-8B) fine-tuned on IntrEx achieved a Gwet's AC2 agreement with human ratings of approximately 0.514, outperforming the 0.4657 score of the much larger GPT-4o. The principal implication for AI practitioners is that high-quality, domain-specific datasets can enable smaller, fine-tuned models to surpass larger, general-purpose models in predicting nuanced, subjective human preferences, providing an efficient approach for building specialized reward models. |
| The Illusion of Diminishing Returns: Measuring Long Horizon Execution in
  LLMs (Read more on [arXiv](https://arxiv.org/abs/2509.09677) or [HuggingFace](https://huggingface.co/papers/2509.09677))| Jonas Geiping, Steffen Staab, Shashwat Goel, arvindh75, viciousa3gis | This paper demonstrates that marginal improvements in single-step accuracy can compound into exponential gains in the length of tasks LLMs can execute. The primary research objective is to isolate and measure the long-horizon execution capability of LLMs, distinct from reasoning or planning, and to diagnose failure modes on long but simple tasks. The key methodology involves a synthetic key-value dictionary addition task where the knowledge (dictionary) and plan (keys to look up) are provided in-context, forcing the model to only perform sequential retrieval and composition. The primary results show that per-step accuracy degrades over time due to a "self-conditioning" effect, where models become more likely to err after observing their own past mistakes; for example, Qwen3-32B's accuracy falls below 50% within 15 turns despite perfect single-step accuracy. The principal implication for AI practitioners is that for long-horizon tasks, enabling sequential test-time compute ("thinking") is critical, as it eliminates the self-conditioning effect and dramatically increases execution length, whereas simply scaling model size does not. |
| X-Part: high fidelity and structure coherent shape decomposition (Read more on [arXiv](https://arxiv.org/abs/2509.08643) or [HuggingFace](https://huggingface.co/papers/2509.08643))| Yunhan Yang, Changfeng Ma, Yang Li, Jiachen Xu, HowieYan | X-Part introduces a controllable diffusion-based model for decomposing holistic 3D objects into high-fidelity, structurally coherent parts. The primary objective is to create a generative framework that provides precise control over part decomposition while ensuring semantic meaning and geometric quality, addressing the limitations of existing segmentation-sensitive or uncontrollable methods. The methodology utilizes a multi-part Diffusion Transformer (DiT) conditioned by bounding box prompts for spatial guidance and injected point-wise semantic features from a P3-SAM segmenter to guide semantically accurate decomposition. The model achieves state-of-the-art performance, demonstrating a Chamfer Distance of 0.11 and an F-score of 0.80 (at threshold 0.1) on the ObjaversePart-Tiny benchmark for part decomposition. For AI practitioners, this work establishes an editable pipeline where 3D assets can be interactively decomposed by manipulating bounding boxes, significantly simplifying downstream tasks like UV mapping and retopology in production environments. |
| InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis (Read more on [arXiv](https://arxiv.org/abs/2509.10441) or [HuggingFace](https://huggingface.co/papers/2509.10441))| Song Guo, Xiaoyu Yue, Junchao Gong, Wanghan Xu, Tao Han | InfGen is a resolution-agnostic generator that replaces the VAE decoder in latent diffusion models to enable efficient, arbitrary high-resolution image synthesis from a fixed-size latent. The main objective is to overcome the quadratic computational scaling and slow inference speeds of current diffusion models when generating high-resolution images. The key methodology involves a transformer-based generator that uses an Implicit Neural Positional Embedding (INPE) to decode a fixed content latent into a variable-resolution image, with a training-free iterative extrapolation process for scaling beyond trained resolutions. Primary results show that InfGen reduces 4K image generation time to under 10 seconds, achieving a 10x speed improvement over prior methods, and improves the FIDp of DiT by 41% at 3072x3072 resolution. The principal implication for AI practitioners is that InfGen acts as a plug-and-play module to upgrade existing diffusion models for arbitrary high-resolution generation without the need for costly retraining of the foundational model. |
| HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented
  Generation for Multi-hop Question Answering (Read more on [arXiv](https://arxiv.org/abs/2509.09713) or [HuggingFace](https://huggingface.co/papers/2509.09713))| Zhehao Tan, Yihan Jiao, Yue Shen, Dan Yang, Duolin Sun | The paper introduces HANRAG, a heuristic framework using a central "Revelator" agent to improve multi-hop Retrieval-Augmented Generation by routing queries, decomposing them, and filtering noise. The primary objective is to overcome key RAG challenges in multi-hop question answering, such as the inefficiency of iterative retrieval, irrational querying, and noise accumulation. The key methodology is a master agent, the Revelator, which classifies queries into four types (straightforward, single-step, compound, complex), decomposes compound queries for parallel retrieval, refines sub-questions for complex queries, and uses a relevance discriminator to filter noisy documents. On a custom multi-hop compound query benchmark, HANRAG achieved an accuracy of 71.76%, a 19.63 percentage point improvement over the Adaptive-RAG baseline, while reducing average retrieval steps from 2.76 to 1.24. For AI practitioners, the principal implication is that implementing a versatile, heuristic-based agent to pre-process and route queries based on complexity can significantly enhance the accuracy and efficiency of RAG systems, providing a more robust solution for handling diverse real-world questions. |
| VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions (Read more on [arXiv](https://arxiv.org/abs/2509.09716) or [HuggingFace](https://huggingface.co/papers/2509.09716))| Dong Zhang, Chen Wang, Yuxuan Xie, Mingyang Han, Jun Zhan | The paper introduces VStyle, a bilingual benchmark, and a LALM-as-a-Judge framework to evaluate the ability of Spoken Language Models (SLMs) to adapt their voice style based on spoken instructions. The primary research objective is to formalize and assess Voice Style Adaptation (VSA), determining if SLMs can modify acoustic and prosodic features like timbre, emotion, and persona in response to natural language commands. The key methodology involves the 1,523-prompt VStyle benchmark and a LALM-as-a-Judge pipeline that hierarchically evaluates outputs on content faithfulness, style adherence, and naturalness. Primary results reveal a significant performance gap between commercial and open-source models, with a top commercial system like GPT-4o scoring 4.05 overall in English while open-source models generally scored between 2 and 3. The principal implication for AI practitioners is that the LALM-as-a-Judge framework, validated with a 77.01% Spearman correlation to human judgment in English, provides a scalable and reproducible method for automatically evaluating the expressive capabilities of speech generation systems. |
| FLOWER: Democratizing Generalist Robot Policies with Efficient
  Vision-Language-Action Flow Policies (Read more on [arXiv](https://arxiv.org/abs/2509.04996) or [HuggingFace](https://huggingface.co/papers/2509.04996))| Fabian Otto, Ömer Erdinç Yağmurlu, Marcel Rühle, Hongyi Zhou, Moritz Reuss | The paper introduces FLOWER, a 950M-parameter Vision-Language-Action (VLA) policy that achieves state-of-the-art performance with significantly reduced computational costs. The research objective is to develop a computationally efficient, generalist VLA policy with fewer than one billion parameters that can match the performance of much larger models across diverse robotic manipulation tasks. The methodology combines intermediate-modality fusion, which prunes 30-50% of a pretrained Vision-Language Model's layers to condition a Rectified Flow transformer, with action-specific Global-AdaLN conditioning to reduce parameters for handling heterogeneous action spaces. Pretrained in just 200 H100 GPU hours, FLOWER achieves a new state-of-the-art score of 4.53 on the CALVIN ABC benchmark and doubles the real-world success rate of OpenVLA (61% vs. 31%). The principal implication for AI practitioners is the ability to develop and deploy high-performance, generalist robot policies on commodity hardware with substantially lower pretraining costs and memory footprints (1.85 GB VRAM), making advanced robotics more accessible. |
| Inpainting-Guided Policy Optimization for Diffusion Large Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2509.10396) or [HuggingFace](https://huggingface.co/papers/2509.10396))| Chenyu Wang, Miao Liu, Jing Huang, Mengchen Liu, Siyan Zhao | This paper presents Inpainting-Guided Policy Optimization (IGPO), a reinforcement learning framework that improves dLLM alignment by using inpainting to guide exploration. The primary objective is to overcome the sample inefficiency and zero-gradient problem caused by sparse rewards in RL, particularly the "zero-advantage dilemma" in group-based methods where all sampled responses are incorrect. The methodology involves strategically injecting partial ground-truth reasoning traces as fixed "hints" during generation when exploration fails, tasking the model with inpainting the missing steps to create successful solutions and restore reward variance. The full training recipe, combining Length-Aligned SFT with IGPO, achieves a new state-of-the-art for full-attention masked dLLMs, improving GSM8K performance by +4.9% to 86.4% over the LLaDA-Instruct baseline. For AI practitioners, this work demonstrates that a dLLM's architectural capabilities, like inpainting, can be directly leveraged to design more sample-efficient and stable RL algorithms for aligning models on complex reasoning tasks. |
| Virtual Agent Economies (Read more on [arXiv](https://arxiv.org/abs/2509.10147) or [HuggingFace](https://huggingface.co/papers/2509.10147))| William A. Cunningham, Julian Jacobs, Joel Z. Leibo, Matija Franklin, Nenad Tomasev | This paper proposes the "sandbox economy" framework to analyze and steer emergent economies of autonomous AI agents using market mechanisms. The main objective is to establish a conceptual framework for proactively designing steerable agent markets to mitigate the risks of systemic instability and inequality associated with a spontaneously emerging, highly permeable agent economy. The methodology is a conceptual analysis that synthesizes principles from economics, social choice theory, and distributed systems, proposing socio-technical infrastructures like auction mechanisms, Verifiable Credentials (VCs), and Decentralized Identifiers (DIDs). The primary result is the "sandbox economy" framework itself, characterized along two dimensions (origins and permeability), which provides a structure for designing intentional agent markets; the paper is theoretical and does not present original quantitative findings. The principal implication for AI practitioners is the need to architect agentic systems with standardized protocols for identity (DIDs), reputation (VCs), and interoperability (A2A) to facilitate their participation in governed, multi-agent market ecosystems, shifting the design focus from single-agent capabilities to the rules of the encompassing economic system. |
| QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading (Read more on [arXiv](https://arxiv.org/abs/2509.09995) or [HuggingFace](https://huggingface.co/papers/2509.09995))| Chenyu You, Siqi Sun, Aosong Feng, Xiang Zhang, Fei Xiong | QuantAgent is a multi-agent LLM framework that uses structured technical analysis of price data for high-frequency trading decisions. The objective is to develop and evaluate an LLM-based system specifically for high-frequency trading that operates solely on structured price data (OHLC), avoiding the latency and noise of traditional text-based financial LLM inputs. The system decomposes the trading task into four specialized agents—Indicator, Pattern, Trend, and Risk—which analyze OHLC data using domain-specific tools for technical indicators, chart patterns, and trend lines; a final Decision Agent integrates these structured outputs to generate a trade signal. In zero-shot evaluations on 4-hour candlestick data, QuantAgent consistently outperformed random baselines across eight financial assets, achieving a directional accuracy of 62.0% on the SPX index, a 59.0% improvement over the baseline's 39.0%. The principal implication for AI practitioners is that a modular, tool-augmented multi-agent architecture can successfully apply LLM reasoning to latency-sensitive, structured-data domains, enabling the development of interpretable and performant automated decision systems by combining LLM capabilities with traditional quantitative methods. |
| LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised
  Learning in Open-World Scenarios (Read more on [arXiv](https://arxiv.org/abs/2509.09926) or [HuggingFace](https://huggingface.co/papers/2509.09926))| Bing Su, Yurou Liu, Zhiyuan Huang, Jiahao Chen | This paper introduces LoFT, a parameter-efficient fine-tuning framework for long-tailed semi-supervised learning (LTSSL) that leverages pre-trained foundation models to improve performance on imbalanced datasets. The objective is to address the overconfidence and poor pseudo-label quality of models trained from scratch, and to extend this approach to open-world scenarios containing out-of-distribution (OOD) data. LoFT applies parameter-efficient fine-tuning (PEFT) on vision transformers, using a confidence threshold to assign hard or soft pseudo-labels, while its extension, LoFT-OW, adds an OOD detection mechanism to filter irrelevant samples. The method achieves up to 83.2% accuracy on CIFAR-100-LT with an OpenCLIP backbone, outperforming previous works while using only 1% of the unlabeled data on ImageNet-127. For AI practitioners, this work demonstrates that using PEFT on foundation models is a highly effective and efficient strategy for LTSSL, providing better model calibration and pseudo-label quality with reduced training overhead compared to training from scratch. |
| MCP-AgentBench: Evaluating Real-World Language Agent Performance with
  MCP-Mediated Tools (Read more on [arXiv](https://arxiv.org/abs/2509.09734) or [HuggingFace](https://huggingface.co/papers/2509.09734))| Xiaorui Wang, Wentao Hong, Chiwei Zhu, Benfeng Xu, Zikang Guo | This paper introduces MCP-AgentBench, a benchmark for evaluating language agent performance in real-world, multi-step tasks using tools mediated by the Model Context Protocol (MCP). The primary objective is to address the critical evaluation gap where existing benchmarks fail to assess agent capabilities within standardized, protocol-driven interaction frameworks. The methodology consists of a testbed with 33 MCP servers and 188 tools, a dataset of 600 categorized queries, and an outcome-oriented LLM-as-a-judge evaluation framework called MCP-Eval. Empirical results show that the open-source model Qwen3-235B-A22B achieved the highest overall pass rate of 64.7% with a ReAct framework, outperforming proprietary models like Claude 4 Sonnet (58.0% with TC). The key implication for AI engineers is that agent performance is critically dependent on the interaction framework (ReAct vs. Tool Calling), necessitating the use of realistic, protocol-aware benchmarks for model selection and validation in building interoperable AI systems. |
| CMHG: A Dataset and Benchmark for Headline Generation of Minority
  Languages in China (Read more on [arXiv](https://arxiv.org/abs/2509.09990) or [HuggingFace](https://huggingface.co/papers/2509.09990))| XU Han, Jianing Liu, Ziyin Zhang, Zeli Su, Guixian Xu | This paper introduces the Chinese Minority Headline Generation (CMHG) dataset, a novel corpus designed to address the scarcity of supervised data for headline generation in Tibetan, Uyghur, and Mongolian. The primary objective is to create and benchmark a large-scale dataset for these low-resource languages. The methodology involved web scraping from government and news sites to collect samples (100k Tibetan, 50k Uyghur, 50k Mongolian), followed by a rigorous annotation process where native speakers curated a high-quality test set of nearly 3,000 samples per language for title-content relevance. The primary results show that few-shot evaluation of large models like LLaMA3.1-70B yielded strong performance, achieving ROUGE-L F1 scores of 0.34 for both Tibetan and Uyghur on the high-quality annotated test set. The principal implication for AI practitioners is the immediate availability of a validated, open-source dataset and benchmark that enables direct fine-tuning and evaluation of generative models for these specific low-resource languages. |
