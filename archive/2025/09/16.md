

## Papers for 2025-09-16

| Title | Authors | Summary |
|-------|---------|---------|
| OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling (Read more on [arXiv](https://arxiv.org/abs/2509.12201) or [HuggingFace](https://huggingface.co/papers/2509.12201))| Yang Zhou, MingyuLiu, Xxxy13, lizizun, ZhouTimeMachine | This paper introduces OmniWorld, a large-scale, multi-domain, multi-modal dataset with over 300 million frames designed to advance 4D world modeling by providing rich geometric and temporal annotations. The primary objective is to address the data scarcity for training and evaluating general 4D world models by creating a comprehensive resource that surpasses existing datasets in scale, modality coverage, and dynamic complexity. The methodology involves collecting a new synthetic dataset, `OmniWorld-Game`, from diverse game environments and developing an extensive pipeline to annotate it and several curated public datasets with high-quality depth, camera poses, text captions, optical flow, and foreground masks. The paper establishes benchmarks that expose limitations in current models and demonstrates that fine-tuning with OmniWorld yields significant performance gains; for example, fine-tuning the AC3D video generation model reduces its camera translation error on the `OmniWorld-Game` benchmark from 6.2788 to 4.1428. For AI practitioners, OmniWorld serves as a powerful training and evaluation resource for developing more robust models for tasks requiring complex spatio-temporal understanding, enabling direct performance improvements in 3D geometric reconstruction and camera-controlled video generation through fine-tuning. |
| UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2509.11543) or [HuggingFace](https://huggingface.co/papers/2509.11543))| Yongliang Shen, Fei Tang, xhyandwyy, Mizukiluke, LZXzju | The paper introduces Semi-online Reinforcement Learning, a paradigm that simulates online RL on static offline trajectories to improve multi-turn reasoning for GUI automation agents. The primary objective is to overcome the limitations of traditional offline RL (poor multi-step performance) and online RL (high cost and sparse rewards) by enabling long-horizon optimization using only pre-collected data. The core methodology involves generating rollouts that maintain the agent's history, using a "Patch Module" to recover from action divergences by injecting expert actions, and optimizing the policy with weighted step-level and episode-level advantages derived from discounted future rewards. The resulting UI-S1-7B model achieves state-of-the-art performance, with significant gains over its base model, including a +12.0% success rate on the AndroidWorld benchmark. For AI practitioners, this framework provides a practical method to train capable multi-turn agents on static datasets, effectively bridging the gap between offline training efficiency and online execution robustness without requiring costly live environment interaction. |
| InternScenes: A Large-scale Simulatable Indoor Scene Dataset with
  Realistic Layouts (Read more on [arXiv](https://arxiv.org/abs/2509.10813) or [HuggingFace](https://huggingface.co/papers/2509.10813))| Wenzhe Cai, Li Luo, Yichen Jin, Peizhou Cao, Weipeng Zhong | InternScenes is a large-scale, simulatable 3D indoor dataset of approximately 40,000 scenes with realistic object layouts, created by integrating real-world scans, procedurally generated scenes, and designer-created content. The objective is to create a diverse and complex dataset for training and benchmarking Embodied AI and 3D AIGC models, addressing the limitations of existing datasets in scale, layout realism, and simulatability. The methodology involves a multi-source data processing pipeline that performs real-to-sim replication, enriches scenes with interactive objects, and uses physics simulation (SAPIEN) to resolve object collisions and ensure physical plausibility. In point-goal navigation benchmarks, a state-of-the-art method like NavDP achieves only a 48.3% success rate on the most realistic subset, indicating the high difficulty of the scenes. For AI practitioners, this dataset serves as a challenging new benchmark to test the robustness of navigation and scene generation models, revealing that current methods struggle significantly with cluttered, realistic environments and require advancements in handling complex object interactions and spatial reasoning. |
| LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion
  Transformers via Explicit Correspondence (Read more on [arXiv](https://arxiv.org/abs/2509.12203) or [HuggingFace](https://huggingface.co/papers/2509.12203))| Lionel M. Ni, Xianfang Zeng, Xili Dai, Zixin Yin, dorni | LazyDrag is a training-free method for drag-based editing in Multi-Modal Diffusion Transformers that uses an explicit correspondence map to achieve stable edits under full-strength inversion without test-time optimization. The primary objective is to eliminate the instability of drag-based editing caused by implicit attention-based point matching by introducing an explicit correspondence mechanism that enables robust, high-fidelity geometric and semantic control. The methodology involves generating an explicit correspondence map from user drag inputs via Voronoi partitioning, which then drives a dual attention control mechanism: hard token replacement for background preservation and token concatenation with gated output blending for identity-preserving edits in dragged regions. LazyDrag achieves state-of-the-art performance on the DragBench benchmark, outperforming all baselines with a mean distance (MD) of 21.49 ± 0.04 and securing a 61.88% preference rate in a human evaluation study. For AI practitioners, this paper provides a robust, optimization-free framework that replaces fragile implicit point matching with a deterministic correspondence map, enabling stable and predictable high-fidelity interactive image editing that integrates precise spatial control with text guidance. |
| Locality in Image Diffusion Models Emerges from Data Statistics (Read more on [arXiv](https://arxiv.org/abs/2509.09672) or [HuggingFace](https://huggingface.co/papers/2509.09672))| Vincent Sitzmann, Justin Solomon, Chenyang Yuan, Artem Lukoianov | This paper demonstrates that the locality property in image diffusion models is not an architectural inductive bias but an emergent statistical property of the training dataset's pixel correlations. The research objective is to show that this generalization behavior is derived directly from the second-order statistics of the training data, rather than from architectural constraints like those in convolutional networks. The key methodology involves theoretically and empirically linking the learned sensitivity fields of diffusion models (both U-Nets and Transformers) to the Wiener filter, which acts as a projection operator onto the high Signal-to-Noise Ratio (SNR) principal components of the data's covariance matrix. The primary result is a new analytical denoiser, based on these data statistics, that better explains the predictions of a trained deep model than prior analytical approaches, achieving a coefficient of determination (r²) of 0.902 on CelebA-HQ compared to 0.795 for the previous best analytical model. For AI practitioners, the principal implication is that the statistical structure of the training data, specifically pixel covariance, is a primary determinant of a diffusion model's learned behavior and generalization patterns, offering a direct lever for model control that is complementary to architectural design. |
| Measuring Epistemic Humility in Multimodal Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.09658) or [HuggingFace](https://huggingface.co/papers/2509.09658))| Kaiyang Zhou, Sifeng Shang, Bingkui Tong, JiaerX | This paper introduces HumbleBench, a benchmark to evaluate the epistemic humility of Multimodal Large Language Models (MLLMs) by testing their ability to reject false-option choices. The research aims to measure whether MLLMs can identify when none of the provided multiple-choice answers are correct and select a "None of the above" (NOTA) option. The methodology involves creating a dataset of 22,831 questions from the Panoptic Scene Graph dataset, using GPT-4-Turbo for generation and manual filtering, where each question includes a NOTA option. The primary result from evaluating 19 state-of-the-art MLLMs is that even the best-performing model, GLM-4.1V-Thinking, achieved only 73.46% accuracy, and in a stress test where NOTA was always the correct answer, most models failed catastrophically, often scoring below the random guess baseline. The principal implication for AI practitioners is that current MLLMs exhibit significant overconfidence and are unreliable in scenarios requiring abstention from incorrect answers, making standard accuracy metrics insufficient for assessing their suitability for safety-critical applications. |
| Lost in Embeddings: Information Loss in Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2509.11986) or [HuggingFace](https://huggingface.co/papers/2509.11986))| Ivan Vulić, Caiqi Zhang, Chengzu Li, Raphael Tang, lyan62 | This paper introduces a framework to quantify information loss in the connector module of Vision-Language Models (VLMs) and correlates this loss with downstream task performance. The research objective is to measure the distortion of visual information when connectors project visual embeddings into the language model's space. The methodology employs two approaches: the k-Nearest Neighbors Overlap Ratio (KNOR) to evaluate geometric distortion and patch-level embedding reconstruction to localize information loss. Results demonstrate that connectors cause a 40-60% divergence in k-nearest neighbor relationships post-projection, and high patch-level reconstruction loss in answer-relevant regions negatively correlates with accuracy on visually-grounded VQA tasks. The principal implication for AI practitioners is that the connector acts as a significant information bottleneck, and the proposed reconstruction method provides an interpretable tool for debugging VLM failures by localizing where critical visual details are lost. |
| CognitiveSky: Scalable Sentiment and Narrative Analysis for
  Decentralized Social Media (Read more on [arXiv](https://arxiv.org/abs/2509.11444) or [HuggingFace](https://huggingface.co/papers/2509.11444))| Subasish Das, Anandi Dutta, gauravfs-14 | This paper introduces CognitiveSky, an open-source framework for scalable, real-time sentiment, emotion, and narrative analysis on the decentralized social media platform Bluesky. The primary objective is to develop a transparent, low-cost tool for computational social science that overcomes the data access limitations of centralized platforms like X.com. The methodology utilizes a Node.js worker for data ingestion from the Bluesky Firehose API, a CI-automated Python pipeline with transformer-based models (RoBERTa for sentiment, DistilRoBERTa for emotion) for annotation, and MiniBatch NMF on TF-IDF vectors for topic modeling. In a mental health discourse use case analyzing 58,567 posts, the system identified "Fear" as the most frequent emotion, accounting for 31.3% of all detected emotions. The principal implication for AI practitioners is the blueprint for a fully automated, reproducible, and serverless architecture built entirely on free-tier infrastructure, enabling the deployment of real-time NLP analysis pipelines on decentralized data streams without significant operational cost. |
| Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2509.12132) or [HuggingFace](https://huggingface.co/papers/2509.12132))| Shuo Ren, Chen Wang, Wei Sun, Junhong Wu, Pu Jian | This paper presents Reflection-V, a training strategy for Vision-Language Models (VLMs) that enhances visual reflection to improve multi-step reasoning by maintaining sustained attention on visual inputs. The primary objective is to address the limitation of existing VLMs, which exhibit rapidly diminishing attention to visual information during long reasoning chains, thereby failing to perform effective visual grounding. The key methodology is a two-stage process: first, a cold-start initialization using reasoning data generated via an interactive LLM-VLM agent framework to embed reflective patterns; second, reinforcement learning with a novel visual attention-based reward to encourage sustained focus on visual tokens. The resulting Reflection-V-7B model achieves state-of-the-art performance, scoring 73.3 on MathVista and 71.1 on M3CoT, significantly outperforming its base model and larger models like InternVL-2.5-38B. For AI practitioners, this research provides a concrete methodology to mitigate visual neglect and reduce hallucinations in VLMs, demonstrating that explicitly training for and rewarding sustained visual attention is critical for building more accurate and reliable visual reasoning systems. |
| Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose
  Video Hallucination by Fine-grained Spatial-Temporal Grounding (Read more on [arXiv](https://arxiv.org/abs/2509.11866) or [HuggingFace](https://huggingface.co/papers/2509.11866))| Li Zheng, Tianjie Ju, Liqiang Jing, Shengqiong Wu, Meng Luo | This paper introduces Dr.V, a framework to diagnose and mitigate video hallucinations in LVMs using a hierarchical, tool-augmented reasoning process grounded in spatial-temporal evidence. The primary objective is to create a comprehensive system for systematically verifying model outputs against video content by first establishing a fine-grained, three-level (perceptive, temporal, cognitive) taxonomy of hallucinations. The methodology consists of Dr.V-Bench, a 10k-instance benchmark with detailed spatial-temporal annotations across 14 hallucination types, and Dr.V-Agent, a training-free system that uses an LLM to dynamically invoke specialized external tools for perceptive and temporal grounding to validate an LVM's claims. Experiments show Dr.V-Agent substantially mitigates hallucinations, improving the accuracy of the Qwen2-VL model by +9.97% absolute (from 72.67% to 82.64%) on the benchmark. For AI practitioners, this work demonstrates that a modular, agentic approach leveraging specialized tools for evidence verification is a highly effective, training-free strategy to improve the factual grounding and reliability of generative video models. |
| EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI (Read more on [arXiv](https://arxiv.org/abs/2509.11648) or [HuggingFace](https://huggingface.co/papers/2509.11648))| UVSKKR | The paper introduces EthicsMH, a pilot benchmark dataset designed to evaluate the ethical reasoning of AI systems in mental health contexts. The primary objective is to create a resource that captures the unique ethical dilemmas in mental health practice, which are inadequately addressed by existing benchmarks. The dataset was constructed via a human-in-the-loop process where an LLM generated initial scenarios that were then iteratively reviewed and validated by a mental health professional for clinical plausibility and ethical nuance. The primary result is the EthicsMH dataset, which contains 125 scenarios evenly distributed across five subcategories, with each scenario featuring structured fields for decision options, expert-aligned reasoning, and multi-stakeholder viewpoints. The principal implication for AI practitioners is that EthicsMH provides a concrete resource for pre-deployment stress-testing, diagnostic evaluation of model tendencies, and prototyping safeguards for AI systems intended for sensitive mental health applications. |
| Learning to Optimize Multi-Objective Alignment Through Dynamic Reward
  Weighting (Read more on [arXiv](https://arxiv.org/abs/2509.11452) or [HuggingFace](https://huggingface.co/papers/2509.11452))| Changlong Yu, Xin Liu, Shiyang Li, Zilong Wang, ylu610 | This paper introduces dynamic reward weighting methods to optimize multi-objective LLM alignment by adaptively adjusting objective importance during online reinforcement learning. The main objective is to overcome the limitations of fixed-weight linear scalarization, which fails to capture non-convex Pareto fronts, by dynamically reallocating learning effort toward objectives with the greatest potential for improvement. The authors propose two key methodologies: (1) hypervolume-guided weight adaptation, which uses a meta-reward to encourage the discovery of new Pareto-optimal solutions based on user preferences, and (2) gradient-based weight optimization, which automatically reallocates weights by computing an objective's influence on the overall training process. The primary result is that the proposed dynamic methods consistently achieve Pareto-dominant solutions with greater training efficiency than fixed-weight baselines; for instance, the gradient-based method reduced the average number of steps to reach the Pareto front by 6.1 across all tested RL algorithms. The principal implication for AI practitioners is that these dynamic weighting techniques, especially the gradient-based approach, can be implemented in multi-objective RLHF pipelines to achieve superior trade-offs between competing objectives like accuracy and conciseness while reducing training steps, eliminating the need for manual weight tuning. |
| PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits (Read more on [arXiv](https://arxiv.org/abs/2509.11362) or [HuggingFace](https://huggingface.co/papers/2509.11362))| Zhenhao Chen, Guangyi Chen, Minghao Fu, Wong Yu Kang, Loka Li | This paper introduces PersonaX, a pair of public multimodal datasets linking LLM-inferred Big Five behavioral traits with facial and biographical data for comprehensive trait analysis. The objective is to facilitate large-scale analysis of human traits across modalities and to develop a framework for learning their underlying causal structures from both structured and unstructured data. Using a novel causal representation learning (CRL) framework with theoretical identifiability guarantees, the method achieved an R² of 0.96 on synthetic data, outperforming baselines, while statistical tests on the datasets revealed population-specific dependencies between traits and attributes like occupation or sports league. For AI practitioners, this work provides curated benchmarks for cross-modal causal discovery and demonstrates that simpler, 3-level numeric prompts yield the most consistent behavioral trait inferences from large language models. |
| GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings (Read more on [arXiv](https://arxiv.org/abs/2509.10844) or [HuggingFace](https://huggingface.co/papers/2509.10844))| Yixuan Tang, yixuantt | The paper presents GAPrune, a novel pruning framework for creating efficient, domain-aware embedding models by balancing domain-specific importance with general linguistic alignment. The main objective is to develop a compression technique for large embedding models that preserves or enhances specialized domain performance while significantly reducing model size. GAPrune characterizes each model parameter using two signals: Fisher Information to quantify its importance for domain and general tasks, and gradient cosine similarity to measure the alignment between domain-specific and general objectives, combining them into a Domain-Alignment Importance (DAI) score for pruning. Experiments show that with 100 steps of retraining at 50% sparsity, GAPrune improves the performance of the Qwen3-Embedding-4B model over its dense counterpart by +4.51% on the FinMTEB benchmark and +1.73% on ChemTEB. The principal implication for AI practitioners is that GAPrune provides a method to compress large embedding models into smaller, domain-specialized versions that are not only more efficient but can also achieve superior performance on target domain tasks after minimal retraining. |
